{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures comparing deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import funcs_helpers as fh\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_path0 = r\"data\\coarseMesh_noBifurcation_5\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_2.pkl\"\n",
    "data_path1 = r\"data\\coarseMesh_noBifurcation_5\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_largerRVE.pkl\"\n",
    "\n",
    "data = {}\n",
    "with open(data_path0, 'rb') as f:\n",
    "    data['reference'] = pickle.load(f)\n",
    "print(data['reference'][0])\n",
    "print(len(data['reference']))\n",
    "\n",
    "with open(data_path1, 'rb') as f:\n",
    "    data['extended RVE'] = pickle.load(f)\n",
    "print(data['extended RVE'][0])\n",
    "print(len(data['extended RVE']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# # only keep validation data\n",
    "# trajs = [graph.traj.numpy() for graph in data['reference']]\n",
    "# train_inds, val_inds = fh.split_trajs(trajs, 2, split_sizes=(0.7, 0.3))\n",
    "\n",
    "# for key in ['reference', 'extended RVE']:\n",
    "#     data[key] = [data[key][ind] for ind in val_inds]\n",
    "\n",
    "# %%\n",
    "# rotate/reflect/scale\n",
    "scale_factor = 1.5\n",
    "R_arr = [torch.tensor([[0.707107, -0.707107],[0.707107, 0.707107]]),  # rot\n",
    "         torch.tensor([[-1.0, -0],[0, 1.0]]),  # refl\n",
    "         torch.tensor([[scale_factor, 0],[0, scale_factor]])]   # scale\n",
    "keys = ['rotated', 'reflected', 'scaled']\n",
    "for R, key in zip(R_arr, keys):\n",
    "    data[key] = []\n",
    "    err = []\n",
    "    for graph in data['reference']:\n",
    "        graph = graph.clone()\n",
    "\n",
    "        R = R.to(graph.y.device)\n",
    "        # print(R.device)\n",
    "        # print(graph.y.device)\n",
    "        graph.y = torch.matmul(R, graph.y.T).T\n",
    "        graph.pos = torch.matmul(R, graph.pos.T).T\n",
    "        graph.r = torch.matmul(R, graph.r.T).T\n",
    "        # graph.mean_pos = torch.matmul(R, graph.mean_pos.T).T\n",
    "        if key == 'scaled':\n",
    "            graph.d = scale_factor*graph.d\n",
    "        if key != 'scaled':\n",
    "            graph.P = torch.einsum('lj,ijk,km->ilm', R, graph.P, R.T)\n",
    "            graph.D = torch.einsum('nj,ok,pl,qm,ijklm->inopq', R, R, R, R, graph.D)\n",
    "            graph.F = torch.einsum('ij,lk,mjk->mil', R, R, graph.F)\n",
    "\n",
    "        graph.mean_pos = torch.mean(graph.y, axis=0, keepdim=True)\n",
    "        # mean_pos2 = torch.mean(graph.y, axis=0, keepdim=True)\n",
    "        # err.append((mean_pos2 - graph.mean_pos).cpu().numpy())\n",
    "        data[key].append(graph)\n",
    "    # print(key, 'MAE in mean_pos:', np.mean(np.abs(err)))\n",
    "\n",
    "# %%\n",
    "# shifted RVE\n",
    "# vector describing how the RVE is shifting\n",
    "shift_vec = torch.tensor([0.8, 0.8])\n",
    "\n",
    "# basis vectors spanning the RVE\n",
    "basis_vecs = torch.tensor([[3.2, 0], [0, 3.2]])  #.to(data['reference'][0].y.device)\n",
    "data['shifted RVE'] = []\n",
    "for graph in data['reference']:\n",
    "    graph = graph.clone()\n",
    "    basis_vecs = basis_vecs.to(graph.y.device)\n",
    "    shift_vec = shift_vec.to(graph.y.device)\n",
    "    graph.pos += shift_vec\n",
    "    graph.y += torch.matmul(graph.F, shift_vec)\n",
    "\n",
    "    bools1 = graph.pos[:, 0] > 1.6\n",
    "    graph.pos[bools1] -= basis_vecs[0]\n",
    "    graph.y[bools1] -= torch.matmul(graph.F, basis_vecs[0])\n",
    "\n",
    "    bools2 = graph.pos[:, 1] > 1.6\n",
    "    graph.pos[bools2] -= basis_vecs[1]\n",
    "    graph.y[bools2] -= torch.matmul(graph.F, basis_vecs[1])\n",
    "\n",
    "    graph.mean_pos = torch.mean(graph.y, dim=0, keepdim=True)\n",
    "    data['shifted RVE'].append(graph)\n",
    "\n",
    "# %% noisy distances (to check how errors grow)\n",
    "data['noisy distances'] = []\n",
    "for graph in data['reference']:\n",
    "    graph = graph.clone()\n",
    "    graph.d += torch.randn(*graph.d.shape)*1e-7\n",
    "    data['noisy distances'].append(graph)\n",
    "\n",
    "data['noisy d and r'] = []\n",
    "for graph in data['reference']:\n",
    "    graph = graph.clone()\n",
    "    graph.d += torch.randn(*graph.d.shape)*1e-7\n",
    "    graph.r += torch.randn(*graph.r.shape)*1e-7\n",
    "    data['noisy d and r'].append(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find specific F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Find specific F\n",
    "\n",
    "F = np.concatenate([graph.F.numpy() for graph in data['reference']])\n",
    "\n",
    "# find specific configurations\n",
    "inds_to_plot = []\n",
    "\n",
    "# biaxial compression (rotational bifurcation only)\n",
    "inds = np.where(((F[:, 0, 1] == 0)*(F[:, 0, 0] < 0.9)*(F[:, 1, 1] < 0.9)))[0]\n",
    "inds_to_plot.append(inds[np.argmin(F[inds, 0, 1])])\n",
    "\n",
    "# biaxial tension\n",
    "inds = np.where((F[:, 0,0] == F[:, 1,1]) * (F[:, 0,1] == 0) * (F[:, 1,0] == 0) * (F[:, 0,0] != 1.0))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 0])])\n",
    "\n",
    "# only shear\n",
    "inds = np.where((F[:, 0, 0] == 1)*(F[:,1,1] == 1))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 1])])\n",
    "\n",
    "# tension + compression (left/right bifurcation only)\n",
    "inds = np.where(((F[:, 0, 1] == 0)*(F[:, 0, 0] > 1.23)*(F[:, 0, 0] < 1.27)*(F[:, 1, 1] < 0.77)*(F[:, 1, 1] > 0.73)))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 0] - F[inds, 1, 1])])\n",
    "\n",
    "# double bifurcation\n",
    "goal_F = np.array([[1.05, 0], [0, 0.8]])\n",
    "MSE = np.mean((F - goal_F)**2, axis=(1,2))\n",
    "inds_to_plot.append(np.argmin(MSE))\n",
    "\n",
    "# # + 4 random cases\n",
    "# rng = np.random.default_rng(seed=42)\n",
    "# inds_to_plot.extend(rng.integers(0, len(F), size=4))\n",
    "\n",
    "print(inds_to_plot)\n",
    "print(F[inds_to_plot])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models, rows: models, columns: test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# %matplotlib qt\n",
    "# create comparison plots deformation\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# with open(data_path3, 'rb') as f:\n",
    "#     data['diameter 0.8'] = pickle.load(f)\n",
    "# del data['diameter 0.8 (buckled)']\n",
    "# del data['diameter 0.8 (unbuckled)']\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{{amsmath}}',\n",
    "    'font.size': 20\n",
    "})\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '855011c4a49340f6a6482a24bae0f874', 'f09812771fec478eb1195216f3ae018d', 'f41d9fe09c2b469f8e70416ff0cc2b8e']\n",
    "# names = ['GNN', 'EGNNmod1', 'EGNNmod2', 'EGNNmod2_bigger']\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '2810e07598f748819b99f6b41b1b2423',\n",
    "#            '39c43c406253405fb16182ea6316652a',\n",
    "#            '855011c4a49340f6a6482a24bae0f874',\n",
    "#            'f09812771fec478eb1195216f3ae018d'\n",
    "#            ]\n",
    "# names = ['GNN',\n",
    "#          'GNN, DA ×1',\n",
    "#          'GNN, DA ×2',\n",
    "#          'EGNNmod1',\n",
    "#          'EGNNmod2',\n",
    "#         #  'EGNNmod2_bigger'\n",
    "#         ]\n",
    "\n",
    "run_ids = ['9453aa73b9ee4b42ac9560ff37693d6f',\n",
    "           'f25933db5e5545388265e2e9261edca3',\n",
    "           '64e45fceb1eb46b6a977851c7123bca8',\n",
    "           '0f54a8a568094a3085cc387fe21c3d38',\n",
    "           'bdca87c393db4da3b387a805426d25d2',\n",
    "           'a49f45e0cc3743ab914283c4ea0e6d60',\n",
    "           'f09812771fec478eb1195216f3ae018d',\n",
    "           ]\n",
    "model_names = ['GNN',\n",
    "         'GNN, DA ×1',\n",
    "         'GNN, DA ×2',\n",
    "         'EGNN',\n",
    "         'EGNN, DA ×1',\n",
    "         'EGNN, DA ×2',\n",
    "         'SimEGNN',\n",
    "        #  'EGNNmod2_bigger'\n",
    "        ]\n",
    "\n",
    "cases = ['reference', 'shifted RVE',\n",
    "                             'extended RVE', 'reflected',\n",
    "                             'rotated', 'scaled',\n",
    "                             # 'diameter 0.8', 'finer mesh'\n",
    "                            ]\n",
    "figs = []\n",
    "axes = []\n",
    "# one separate plot for each F\n",
    "for ind in inds_to_plot:\n",
    "    fig, ax = plt.subplots(len(run_ids), len(cases), figsize=(20, 25))\n",
    "    figs.append(fig)\n",
    "    axes.append(ax)\n",
    "\n",
    "for i, [run_id, name] in enumerate(zip(run_ids, model_names)):\n",
    "    print('================================================')\n",
    "    print('testing model', name)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # import model\n",
    "\n",
    "    art_path = client.get_run(run_id).info.artifact_uri[8:]\n",
    "    print(art_path)\n",
    "\n",
    "    # Fetch the logged artifacts\n",
    "    artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "    # find the files with the weights of the model and the parameters needed to initialize it\n",
    "    for artifact in artifacts:\n",
    "        if 'weights.pt' in artifact.path:\n",
    "            model_path = os.path.join(art_path, artifact.path)\n",
    "            print(model_path)\n",
    "        elif artifact.path.endswith('model_init_params.pkl'):\n",
    "            init_params_path = os.path.join(art_path, artifact.path)\n",
    "            print(init_params_path)\n",
    "\n",
    "    # import initialization parameters\n",
    "    with open(init_params_path, 'rb') as f:\n",
    "        init_params = pickle.load(f)\n",
    "\n",
    "    # make sure model definition is imported from the right directory\n",
    "    sys.path.insert(0, art_path)\n",
    "\n",
    "    # import model definition\n",
    "    files = os.listdir(art_path)\n",
    "    fleur_GNN_definition = [file for file in files if file.startswith('fleur_GNN')]\n",
    "    if len(fleur_GNN_definition) > 1:\n",
    "        raise Exception('Multiple fleur_GNN definitions found')\n",
    "    elif len(fleur_GNN_definition) == 0:\n",
    "        raise Exception('No fleur_GNN definition found')\n",
    "\n",
    "    fG = importlib.import_module(fleur_GNN_definition[0].split('.')[0])\n",
    "    fG = importlib.reload(fG)\n",
    "\n",
    "    # create model, load params\n",
    "    model = fG.MyGNN(**init_params)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(model)\n",
    "\n",
    "    scaling_factors = eval(mlflow.get_run(run_id).data.params['scaling_factors'])\n",
    "    print('scaling_factors:', scaling_factors)\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "    # iterate over different test cases\n",
    "    for j, key in enumerate(cases):\n",
    "        print(key)\n",
    "\n",
    "        for k, ind in enumerate(inds_to_plot):\n",
    "            ax = axes[k][i][j]\n",
    "\n",
    "            if key in ['finer mesh', 'diameter 0.8']:\n",
    "                F2 = np.concatenate([graph.F.numpy() for graph in data[key]])\n",
    "\n",
    "                # find same F in different dataset\n",
    "                MSE = np.mean((F2 - F[ind])**2, axis=(1,2))\n",
    "                ind = np.argmin(MSE)\n",
    "\n",
    "            # get all relevant positions\n",
    "            graph = data[key][ind].clone().to(device)\n",
    "            graph.batch = torch.zeros(len(graph.x), dtype=torch.long).to(device)\n",
    "            pos2 = model(graph)[0].clone().cpu().detach().numpy()  # predicted\n",
    "\n",
    "            pos1_temp = graph.pos.clone().cpu().detach().reshape(-1, 2, 1)  # original\n",
    "            pos1 = torch.matmul(graph.F.cpu(), pos1_temp).reshape(-1, 2).numpy()  # affine\n",
    "            pos1_temp = pos1_temp.numpy()\n",
    "\n",
    "            pos3 = graph.y.clone().cpu().detach().numpy()  # target\n",
    "\n",
    "            graph_indices = graph.edge_index.cpu().detach().numpy()\n",
    "\n",
    "            # plot nodes\n",
    "            # ax.scatter(*(pos1.T), label='affine position', s=1)\n",
    "            ax.scatter(*(pos3.T), label='final position', s=1)\n",
    "            ax.scatter(*(pos2.T), label='GNN prediction', s=1)\n",
    "\n",
    "\n",
    "            # plot edges\n",
    "            # x, y = np.transpose(pos1[graph_indices], axes=[2,0,1])\n",
    "            # edges1 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:blue')  #, label='affine position')\n",
    "            x, y = np.transpose(pos1_temp[...,0][graph_indices], axes=[2,0,1])\n",
    "            # exclude wraparound edges\n",
    "            bools = ((np.abs(np.diff(x, axis=0)) < 1.6)\n",
    "                        & (np.abs(np.diff(y, axis=0)) < 1.6)\n",
    "                        & (graph.edge_attr.cpu().numpy() == -1).T\n",
    "                    ).flatten()\n",
    "            x, y = np.transpose(pos3[graph_indices], axes=[2,0,1])\n",
    "            edges3 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:green')  #, label='final position')\n",
    "            x, y = np.transpose(pos2[graph_indices], axes=[2,0,1])\n",
    "            edges2 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:orange')  #, label='GNN prediction')\n",
    "\n",
    "            # # plot fixed node\n",
    "            # fixed_node = ax.scatter(*pos1[graph.fixed_corner_ind].T, s=20, c='magenta', label='fixed node')\n",
    "\n",
    "            # plot original locations corners\n",
    "            corner_coords = np.array([[-1.6, -1.6, 1.6, 1.6],[-1.6, 1.6, 1.6, -1.6]])\n",
    "            if key == 'scaled':\n",
    "                corner_coords *= scale_factor\n",
    "            elif key == 'extended RVE':\n",
    "                corner_coords = np.array([[-1.6, -1.6, 1.6 + 3.2, 1.6 + 3.2],[-1.6, 1.6 + 3.2, 1.6 + 3.2, -1.6]])\n",
    "            elif key == 'rotated':\n",
    "                R =  np.array([[0.707107, -0.707107],[0.707107, 0.707107]])\n",
    "                corner_coords = np.matmul(R, corner_coords)\n",
    "            orig_corners = ax.scatter(*corner_coords, marker='x',\n",
    "                                      label='original corners', c='red', s=20, zorder=10)\n",
    "\n",
    "            # plot new locations corners\n",
    "            corner_coords = np.matmul(graph.F.cpu().numpy(), corner_coords)[0]\n",
    "            # new_corners = ax.scatter(*corner_coords, marker='x', label='new corners', c='red', s=20)\n",
    "            ax.fill(*corner_coords, facecolor='lightgray')\n",
    "\n",
    "            if i == 0:  # first model\n",
    "                ax.set_title(f'{key}', size=22)\n",
    "            if j == 0:  # first test case\n",
    "                ax.set_ylabel(f'{name}', size=22)\n",
    "\n",
    "            # make plot square\n",
    "            xlims = ax.get_xlim()\n",
    "            ylims = ax.get_ylim()\n",
    "            low = min(xlims[0], ylims[0])\n",
    "            high = max(xlims[1], ylims[1])\n",
    "            ax.set_xlim([low, high])\n",
    "            ax.set_ylim([low, high])\n",
    "\n",
    "            # ax.set_title(f'F={graph.F.detach().numpy()[0]}')\n",
    "            # F_temp = graph.F.detach().cpu().numpy()[0]\n",
    "            # temp_str = r'$\\textbf{\\textrm{F}}=\\begin{bmatrix}' + str(F_temp[0,0]) + ' & ' + str(F_temp[0, 1]) + r'\\\\' + str(F_temp[1, 0]) + ' & ' + str(F_temp[1, 1]) + r'\\end{bmatrix}$'\n",
    "            # ax.set_title(temp_str)\n",
    "\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "for fig, ind in zip(figs, inds_to_plot):\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    # fig.suptitle(f'{F[ind]}')\n",
    "    path = f'results/final_results/compare_deformations/compare_deformations_all_models_F=[{F[ind][0]},{F[ind][1]}]'\n",
    "    path = path.replace(' ', '_')\n",
    "    # fig.savefig(path + '.svg', ddpi=300)\n",
    "    # fig.savefig(path + '.pdf', ddpi=300)\n",
    "    # fig.savefig(path + '.png', ddpi=300)\n",
    "    fig.savefig(path + '.png', ddpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only DA ×2 + SimEGNN, no RVE in-/equivariance, rows: test cases, columns: models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# %matplotlib qt\n",
    "# create comparison plots deformation\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# with open(data_path3, 'rb') as f:\n",
    "#     data['diameter 0.8'] = pickle.load(f)\n",
    "# del data['diameter 0.8 (buckled)']\n",
    "# del data['diameter 0.8 (unbuckled)']\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{{amsmath}}',\n",
    "    'font.size': 22\n",
    "})\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '855011c4a49340f6a6482a24bae0f874', 'f09812771fec478eb1195216f3ae018d', 'f41d9fe09c2b469f8e70416ff0cc2b8e']\n",
    "# names = ['GNN', 'EGNNmod1', 'EGNNmod2', 'EGNNmod2_bigger']\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '2810e07598f748819b99f6b41b1b2423',\n",
    "#            '39c43c406253405fb16182ea6316652a',\n",
    "#            '855011c4a49340f6a6482a24bae0f874',\n",
    "#            'f09812771fec478eb1195216f3ae018d'\n",
    "#            ]\n",
    "# names = ['GNN',\n",
    "#          'GNN, DA ×1',\n",
    "#          'GNN, DA ×2',\n",
    "#          'EGNNmod1',\n",
    "#          'EGNNmod2',\n",
    "#         #  'EGNNmod2_bigger'\n",
    "#         ]\n",
    "\n",
    "run_ids = [\n",
    "            '9453aa73b9ee4b42ac9560ff37693d6f', # GNN\n",
    "        #    'f25933db5e5545388265e2e9261edca3',  # GNN\n",
    "        #    '64e45fceb1eb46b6a977851c7123bca8',    # GNN\n",
    "           '0f54a8a568094a3085cc387fe21c3d38',    # EGNN\n",
    "        #    'bdca87c393db4da3b387a805426d25d2',    # EGNN\n",
    "        #    'a49f45e0cc3743ab914283c4ea0e6d60',      # EGNN\n",
    "           'f09812771fec478eb1195216f3ae018d',      # SimEGNN\n",
    "           ]\n",
    "model_names = [\n",
    "        'GNN',\n",
    "        #  'GNN, DA ×1',\n",
    "        #  'GNN, DA ×2',\n",
    "         'EGNN',\n",
    "        #  'EGNN, DA ×1',\n",
    "        #  'EGNN, DA ×2',\n",
    "         'SimEGNN',\n",
    "        #  'EGNNmod2_bigger'\n",
    "        ]\n",
    "\n",
    "cases = ['reference',\n",
    "        #  'shifted RVE',\n",
    "        #  'extended RVE',\n",
    "         'reflected',\n",
    "         'rotated',\n",
    "         'scaled',\n",
    "        # 'diameter 0.8', 'finer mesh'\n",
    "        ]\n",
    "figs = []\n",
    "axes = []\n",
    "# one separate plot for only the first F\n",
    "for ind in inds_to_plot[:1]:\n",
    "    fig, ax = plt.subplots(len(cases),len(run_ids), figsize=(12, 15))\n",
    "    figs.append(fig)\n",
    "    axes.append(ax)\n",
    "\n",
    "for i, [run_id, name] in enumerate(zip(run_ids, model_names)):\n",
    "    print('================================================')\n",
    "    print('testing model', name)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # import model\n",
    "\n",
    "    art_path = client.get_run(run_id).info.artifact_uri[8:]\n",
    "    print(art_path)\n",
    "\n",
    "    # Fetch the logged artifacts\n",
    "    artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "    # find the files with the weights of the model and the parameters needed to initialize it\n",
    "    for artifact in artifacts:\n",
    "        if 'weights.pt' in artifact.path:\n",
    "            model_path = os.path.join(art_path, artifact.path)\n",
    "            print(model_path)\n",
    "        elif artifact.path.endswith('model_init_params.pkl'):\n",
    "            init_params_path = os.path.join(art_path, artifact.path)\n",
    "            print(init_params_path)\n",
    "\n",
    "    # import initialization parameters\n",
    "    with open(init_params_path, 'rb') as f:\n",
    "        init_params = pickle.load(f)\n",
    "\n",
    "    # make sure model definition is imported from the right directory\n",
    "    sys.path.insert(0, art_path)\n",
    "\n",
    "    # import model definition\n",
    "    files = os.listdir(art_path)\n",
    "    fleur_GNN_definition = [file for file in files if file.startswith('fleur_GNN')]\n",
    "    if len(fleur_GNN_definition) > 1:\n",
    "        raise Exception('Multiple fleur_GNN definitions found')\n",
    "    elif len(fleur_GNN_definition) == 0:\n",
    "        raise Exception('No fleur_GNN definition found')\n",
    "\n",
    "    fG = importlib.import_module(fleur_GNN_definition[0].split('.')[0])\n",
    "    fG = importlib.reload(fG)\n",
    "\n",
    "    # create model, load params\n",
    "    model = fG.MyGNN(**init_params)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(model)\n",
    "\n",
    "    scaling_factors = eval(mlflow.get_run(run_id).data.params['scaling_factors'])\n",
    "    print('scaling_factors:', scaling_factors)\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "    # iterate over different test cases\n",
    "    for j, key in enumerate(cases):\n",
    "        print(key)\n",
    "\n",
    "        for k, ind in enumerate(inds_to_plot[:1]):\n",
    "            ax = axes[k][j][i]\n",
    "\n",
    "            if key in ['finer mesh', 'diameter 0.8']:\n",
    "                F2 = np.concatenate([graph.F.numpy() for graph in data[key]])\n",
    "\n",
    "                # find same F in different dataset\n",
    "                MSE = np.mean((F2 - F[ind])**2, axis=(1,2))\n",
    "                ind = np.argmin(MSE)\n",
    "\n",
    "            # get all relevant positions\n",
    "            graph = data[key][ind].clone().to(device)\n",
    "            graph.batch = torch.zeros(len(graph.x), dtype=torch.long).to(device)\n",
    "            pos2 = model(graph)[0].clone().cpu().detach().numpy()  # predicted\n",
    "\n",
    "            pos1_temp = graph.pos.clone().cpu().detach().reshape(-1, 2, 1)  # original\n",
    "            pos1 = torch.matmul(graph.F.cpu(), pos1_temp).reshape(-1, 2).numpy()  # affine\n",
    "            pos1_temp = pos1_temp.numpy()\n",
    "\n",
    "            pos3 = graph.y.clone().cpu().detach().numpy()  # target\n",
    "\n",
    "            graph_indices = graph.edge_index.cpu().detach().numpy()\n",
    "\n",
    "            # plot nodes\n",
    "            # ax.scatter(*(pos1.T), label='affine position', s=1)\n",
    "            ax.scatter(*(pos3.T), label='final position', s=1)\n",
    "            ax.scatter(*(pos2.T), label='GNN prediction', s=1)\n",
    "\n",
    "\n",
    "            # plot edges\n",
    "            # x, y = np.transpose(pos1[graph_indices], axes=[2,0,1])\n",
    "            # edges1 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:blue')  #, label='affine position')\n",
    "            x, y = np.transpose(pos1_temp[...,0][graph_indices], axes=[2,0,1])\n",
    "            # exclude wraparound edges\n",
    "            bools = ((np.abs(np.diff(x, axis=0)) < 1.6)\n",
    "                        & (np.abs(np.diff(y, axis=0)) < 1.6)\n",
    "                        & (graph.edge_attr.cpu().numpy() == -1).T\n",
    "                    ).flatten()\n",
    "            x, y = np.transpose(pos3[graph_indices], axes=[2,0,1])\n",
    "            edges3 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:green')  #, label='final position')\n",
    "            x, y = np.transpose(pos2[graph_indices], axes=[2,0,1])\n",
    "            edges2 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:orange')  #, label='GNN prediction')\n",
    "\n",
    "            # # plot fixed node\n",
    "            # fixed_node = ax.scatter(*pos1[graph.fixed_corner_ind].T, s=20, c='magenta', label='fixed node')\n",
    "\n",
    "            # plot original locations corners\n",
    "            corner_coords = np.array([[-1.6, -1.6, 1.6, 1.6],[-1.6, 1.6, 1.6, -1.6]])\n",
    "            if key == 'scaled':\n",
    "                corner_coords *= scale_factor\n",
    "            elif key == 'extended RVE':\n",
    "                corner_coords = np.array([[-1.6, -1.6, 1.6 + 3.2, 1.6 + 3.2],[-1.6, 1.6 + 3.2, 1.6 + 3.2, -1.6]])\n",
    "            elif key == 'rotated':\n",
    "                R =  np.array([[0.707107, -0.707107],[0.707107, 0.707107]])\n",
    "                corner_coords = np.matmul(R, corner_coords)\n",
    "            orig_corners = ax.scatter(*corner_coords, marker='x',\n",
    "                                      label='original corners', c='red', s=20, zorder=10)\n",
    "\n",
    "            # plot new locations corners\n",
    "            corner_coords = np.matmul(graph.F.cpu().numpy(), corner_coords)[0]\n",
    "            # new_corners = ax.scatter(*corner_coords, marker='x', label='new corners', c='red', s=20)\n",
    "            ax.fill(*corner_coords, facecolor='lightgray')\n",
    "\n",
    "            if i == 0:  # first model\n",
    "                ax.set_ylabel(f'{key}', size=24)\n",
    "            if j == 0:  # first test case\n",
    "                ax.set_title(f'{name}', size=24)\n",
    "\n",
    "            # make plot square\n",
    "            xlims = ax.get_xlim()\n",
    "            ylims = ax.get_ylim()\n",
    "            low = min(xlims[0], ylims[0])\n",
    "            high = max(xlims[1], ylims[1])\n",
    "            ax.set_xlim([low, high])\n",
    "            ax.set_ylim([low, high])\n",
    "\n",
    "            # ax.set_title(f'F={graph.F.detach().numpy()[0]}')\n",
    "            # F_temp = graph.F.detach().cpu().numpy()[0]\n",
    "            # temp_str = r'$\\textbf{\\textrm{F}}=\\begin{bmatrix}' + str(F_temp[0,0]) + ' & ' + str(F_temp[0, 1]) + r'\\\\' + str(F_temp[1, 0]) + ' & ' + str(F_temp[1, 1]) + r'\\end{bmatrix}$'\n",
    "            # ax.set_title(temp_str)\n",
    "\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "for fig, ind in zip(figs, inds_to_plot):\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.35)\n",
    "    # fig.suptitle(f'{F[ind]}')\n",
    "    path = f'results/final_results/compare_deformations/compare_deformations_3_models_F=[{F[ind][0]},{F[ind][1]}]'\n",
    "    path = path.replace(' ', '_')\n",
    "    # fig.savefig(path + '.svg', ddpi=300)\n",
    "    # fig.savefig(path + '.pdf', ddpi=300)\n",
    "    fig.savefig(path + '.png', ddpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No data augmentation, rows: models, columns: test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import funcs_helpers as fh\n",
    "import mlflow\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# load data\n",
    "data_path0 = r\"data\\coarseMesh_noBifurcation_5\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_2.pkl\"\n",
    "data_path1 = r\"data\\coarseMesh_noBifurcation_5\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_largerRVE.pkl\"\n",
    "\n",
    "data = {}\n",
    "with open(data_path0, 'rb') as f:\n",
    "    data['untransformed'] = pickle.load(f)\n",
    "print(data['untransformed'][0])\n",
    "print(len(data['untransformed']))\n",
    "\n",
    "with open(data_path1, 'rb') as f:\n",
    "    data['extended RVE'] = pickle.load(f)\n",
    "print(data['extended RVE'][0])\n",
    "print(len(data['extended RVE']))\n",
    "\n",
    "# %%\n",
    "for key in data: print(key, len(data[key]))\n",
    "\n",
    "# %%\n",
    "# only keep validation data\n",
    "trajs = [graph.traj.numpy() for graph in data['untransformed']]\n",
    "train_inds, val_inds = fh.split_trajs(trajs, 2, split_sizes=(0.7, 0.3))\n",
    "\n",
    "for key in ['untransformed', 'extended RVE']:\n",
    "    data[key] = [data[key][ind] for ind in val_inds]\n",
    "\n",
    "# %%\n",
    "# rotate/reflect/scale\n",
    "scale_factor = 1.5\n",
    "R_arr = [torch.tensor([[0.707107, -0.707107],[0.707107, 0.707107]]),  # rot\n",
    "         torch.tensor([[-1.0, -0],[0, 1.0]]),  # refl\n",
    "         torch.tensor([[scale_factor, 0],[0, scale_factor]])]   # scale\n",
    "keys = ['rotated', 'reflected', 'scaled']\n",
    "for R, key in zip(R_arr, keys):\n",
    "    data[key] = []\n",
    "    err = []\n",
    "    for graph in data['untransformed']:\n",
    "        graph = graph.clone()\n",
    "\n",
    "        R = R.to(graph.y.device)\n",
    "        graph.y = torch.matmul(R, graph.y.T).T\n",
    "        graph.pos = torch.matmul(R, graph.pos.T).T\n",
    "        graph.r = torch.matmul(R, graph.r.T).T\n",
    "        # graph.mean_pos = torch.matmul(R, graph.mean_pos.T).T\n",
    "        if key == 'scaled':\n",
    "            graph.d = scale_factor*graph.d\n",
    "        if key != 'scaled':\n",
    "            graph.P = torch.einsum('lj,ijk,km->ilm', R, graph.P, R.T)\n",
    "            graph.D = torch.einsum('nj,ok,pl,qm,ijklm->inopq', R, R, R, R, graph.D)\n",
    "            graph.F = torch.einsum('ij,lk,mjk->mil', R, R, graph.F)\n",
    "\n",
    "        graph.mean_pos = torch.mean(graph.y, axis=0, keepdim=True)\n",
    "        data[key].append(graph)\n",
    "\n",
    "# %%\n",
    "# shifted RVE\n",
    "# vector describing how the RVE is shifting\n",
    "shift_vec = torch.tensor([0.8, 0.8])\n",
    "\n",
    "# basis vectors spanning the RVE\n",
    "basis_vecs = torch.tensor([[3.2, 0], [0, 3.2]])  #.to(data['untransformed'][0].y.device)\n",
    "data['shifted RVE'] = []\n",
    "for graph in data['untransformed']:\n",
    "    graph = graph.clone()\n",
    "    basis_vecs = basis_vecs.to(graph.y.device)\n",
    "    shift_vec = shift_vec.to(graph.y.device)\n",
    "    graph.pos += shift_vec\n",
    "    graph.y += torch.matmul(graph.F, shift_vec)\n",
    "\n",
    "    bools1 = graph.pos[:, 0] > 1.6\n",
    "    graph.pos[bools1] -= basis_vecs[0]\n",
    "    graph.y[bools1] -= torch.matmul(graph.F, basis_vecs[0])\n",
    "\n",
    "    bools2 = graph.pos[:, 1] > 1.6\n",
    "    graph.pos[bools2] -= basis_vecs[1]\n",
    "    graph.y[bools2] -= torch.matmul(graph.F, basis_vecs[1])\n",
    "\n",
    "    graph.mean_pos = torch.mean(graph.y, dim=0, keepdim=True)\n",
    "    data['shifted RVE'].append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = ['9453aa73b9ee4b42ac9560ff37693d6f',\n",
    "           '0f54a8a568094a3085cc387fe21c3d38',\n",
    "           'f09812771fec478eb1195216f3ae018d',\n",
    "           ]\n",
    "model_names = ['GNN',\n",
    "         'EGNN',\n",
    "         'SimEGNN',\n",
    "        #  'EGNNmod2_bigger'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Find specific F\n",
    "\n",
    "F = np.concatenate([graph.F.numpy() for graph in data['untransformed']])\n",
    "\n",
    "# find specific configurations\n",
    "inds_to_plot = []\n",
    "\n",
    "# biaxial tension\n",
    "inds = np.where((F[:, 0,0] == F[:, 1,1]) * (F[:, 0,1] == 0) * (F[:, 1,0] == 0) * (F[:, 0,0] != 1.0))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 0])])\n",
    "\n",
    "# only shear\n",
    "inds = np.where((F[:, 0, 0] == 1)*(F[:,1,1] == 1))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 1])])\n",
    "\n",
    "# biaxial compression\n",
    "inds = np.where(((F[:, 0, 1] == 0)*(F[:, 0, 0] < 0.9)*(F[:, 1, 1] < 0.9)))[0]\n",
    "inds_to_plot.append(inds[np.argmin(F[inds, 0, 1])])\n",
    "\n",
    "# tension + compression\n",
    "inds = np.where(((F[:, 0, 1] == 0)*(F[:, 0, 0] > 1.2)*(F[:, 1, 1] < 0.9)))[0]\n",
    "inds_to_plot.append(inds[np.argmax(F[inds, 0, 0] - F[inds, 1, 1])])\n",
    "\n",
    "# double bifurcation\n",
    "goal_F = np.array([[1.05, 0], [0, 1-0.2]])\n",
    "MSE = np.mean((F - goal_F)**2, axis=(1,2))\n",
    "inds_to_plot.append(np.argmin(MSE))\n",
    "\n",
    "# + 4 random cases\n",
    "rng = np.random.default_rng(seed=42)\n",
    "inds_to_plot.extend(rng.integers(0, len(F), size=4))\n",
    "\n",
    "print(inds_to_plot)\n",
    "print(F[inds_to_plot])\n",
    "\n",
    "# %%\n",
    "# %matplotlib qt\n",
    "# create comparison plots deformation\n",
    "figs = []\n",
    "axes = []\n",
    "# one separate plot for each F\n",
    "for ind in inds_to_plot:\n",
    "    fig, ax = plt.subplots(len(run_ids), len(data.keys()), figsize=(15, 9))\n",
    "    figs.append(fig)\n",
    "    axes.append(ax)\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# with open(data_path3, 'rb') as f:\n",
    "#     data['diameter 0.8'] = pickle.load(f)\n",
    "# del data['diameter 0.8 (buckled)']\n",
    "# del data['diameter 0.8 (unbuckled)']\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{{amsmath}}',\n",
    "    'font.size': 16\n",
    "})\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '855011c4a49340f6a6482a24bae0f874', 'f09812771fec478eb1195216f3ae018d', 'f41d9fe09c2b469f8e70416ff0cc2b8e']\n",
    "# names = ['GNN', 'EGNNmod1', 'EGNNmod2', 'EGNNmod2_bigger']\n",
    "# run_ids = ['0cb58709c97f428b9bdff611b554c2df',\n",
    "#            '2810e07598f748819b99f6b41b1b2423',\n",
    "#            '39c43c406253405fb16182ea6316652a',\n",
    "#            '855011c4a49340f6a6482a24bae0f874',\n",
    "#            'f09812771fec478eb1195216f3ae018d'\n",
    "#            ]\n",
    "# names = ['GNN',\n",
    "#          'GNN, DA ×1',\n",
    "#          'GNN, DA ×2',\n",
    "#          'EGNNmod1',\n",
    "#          'EGNNmod2',\n",
    "#         #  'EGNNmod2_bigger'\n",
    "#         ]\n",
    "for i, [run_id, name] in enumerate(zip(run_ids, model_names)):\n",
    "    print('================================================')\n",
    "    print('testing model', name)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # import model\n",
    "\n",
    "    art_path = client.get_run(run_id).info.artifact_uri[8:]\n",
    "    print(art_path)\n",
    "\n",
    "    # Fetch the logged artifacts\n",
    "    artifacts = client.list_artifacts(run_id)\n",
    "\n",
    "    # find the files with the weights of the model and the parameters needed to initialize it\n",
    "    for artifact in artifacts:\n",
    "        if 'weights.pt' in artifact.path:\n",
    "            model_path = os.path.join(art_path, artifact.path)\n",
    "            print(model_path)\n",
    "        elif artifact.path.endswith('model_init_params.pkl'):\n",
    "            init_params_path = os.path.join(art_path, artifact.path)\n",
    "            print(init_params_path)\n",
    "\n",
    "    # import initialization parameters\n",
    "    with open(init_params_path, 'rb') as f:\n",
    "        init_params = pickle.load(f)\n",
    "\n",
    "    # make sure model definition is imported from the right directory\n",
    "    sys.path.insert(0, art_path)\n",
    "\n",
    "    # import model definition\n",
    "    files = os.listdir(art_path)\n",
    "    fleur_GNN_definition = [file for file in files if file.startswith('fleur_GNN')]\n",
    "    if len(fleur_GNN_definition) > 1:\n",
    "        raise Exception('Multiple fleur_GNN definitions found')\n",
    "    elif len(fleur_GNN_definition) == 0:\n",
    "        raise Exception('No fleur_GNN definition found')\n",
    "\n",
    "    fG = importlib.import_module(fleur_GNN_definition[0].split('.')[0])\n",
    "    fG = importlib.reload(fG)\n",
    "\n",
    "    # create model, load params\n",
    "    model = fG.MyGNN(**init_params)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(model)\n",
    "\n",
    "    scaling_factors = eval(mlflow.get_run(run_id).data.params['scaling_factors'])\n",
    "    print('scaling_factors:', scaling_factors)\n",
    "    device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "\n",
    "    # iterate over different test cases\n",
    "    for j, key in enumerate(['untransformed', 'shifted RVE',\n",
    "                             'extended RVE', 'reflected',\n",
    "                             'rotated', 'scaled',\n",
    "                             # 'diameter 0.8', 'finer mesh'\n",
    "                            ]):\n",
    "        print(key)\n",
    "\n",
    "        for k, ind in enumerate(inds_to_plot):\n",
    "            ax = axes[k][i][j]\n",
    "\n",
    "            if key in ['finer mesh', 'diameter 0.8']:\n",
    "                F2 = np.concatenate([graph.F.numpy() for graph in data[key]])\n",
    "\n",
    "                # find same F in different dataset\n",
    "                MSE = np.mean((F2 - F[ind])**2, axis=(1,2))\n",
    "                ind = np.argmin(MSE)\n",
    "\n",
    "            # get all relevant positions\n",
    "            graph = data[key][ind].clone().to(device)\n",
    "            graph.batch = torch.zeros(len(graph.x), dtype=torch.long).to(device)\n",
    "            pos2 = model(graph)[0].clone().cpu().detach().numpy()  # predicted\n",
    "\n",
    "            pos1_temp = graph.pos.clone().cpu().detach().reshape(-1, 2, 1)  # original\n",
    "            pos1 = torch.matmul(graph.F.cpu(), pos1_temp).reshape(-1, 2).numpy()  # affine\n",
    "            pos1_temp = pos1_temp.numpy()\n",
    "\n",
    "            pos3 = graph.y.clone().cpu().detach().numpy()  # target\n",
    "\n",
    "            graph_indices = graph.edge_index.cpu().detach().numpy()\n",
    "\n",
    "            # plot nodes\n",
    "            # ax.scatter(*(pos1.T), label='affine position', s=1)\n",
    "            ax.scatter(*(pos3.T), label='final position', s=1)\n",
    "            ax.scatter(*(pos2.T), label='GNN prediction', s=1)\n",
    "\n",
    "\n",
    "            # plot edges\n",
    "            # x, y = np.transpose(pos1[graph_indices], axes=[2,0,1])\n",
    "            # edges1 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:blue')  #, label='affine position')\n",
    "            x, y = np.transpose(pos1_temp[...,0][graph_indices], axes=[2,0,1])\n",
    "            # exclude wraparound edges\n",
    "            bools = ((np.abs(np.diff(x, axis=0)) < 1.6)\n",
    "                        & (np.abs(np.diff(y, axis=0)) < 1.6)\n",
    "                        & (graph.edge_attr.cpu().numpy() == -1).T\n",
    "                    ).flatten()\n",
    "            x, y = np.transpose(pos3[graph_indices], axes=[2,0,1])\n",
    "            edges3 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:green')  #, label='final position')\n",
    "            x, y = np.transpose(pos2[graph_indices], axes=[2,0,1])\n",
    "            edges2 = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:orange')  #, label='GNN prediction')\n",
    "\n",
    "            # # plot fixed node\n",
    "            # fixed_node = ax.scatter(*pos1[graph.fixed_corner_ind].T, s=20, c='magenta', label='fixed node')\n",
    "\n",
    "            # plot original locations corners\n",
    "            corner_coords = np.array([[-1.6, -1.6, 1.6, 1.6],[-1.6, 1.6, 1.6, -1.6]])\n",
    "            if key == 'scaled':\n",
    "                corner_coords *= scale_factor\n",
    "            elif key == 'extended RVE':\n",
    "                corner_coords = np.array([[-1.6, -1.6, 1.6 + 3.2, 1.6 + 3.2],[-1.6, 1.6 + 3.2, 1.6 + 3.2, -1.6]])\n",
    "            elif key == 'rotated':\n",
    "                R =  np.array([[0.707107, -0.707107],[0.707107, 0.707107]])\n",
    "                corner_coords = np.matmul(R, corner_coords)\n",
    "            orig_corners = ax.scatter(*corner_coords, marker='x',\n",
    "                                      label='original corners', c='red', s=20, zorder=10)\n",
    "\n",
    "            # plot new locations corners\n",
    "            corner_coords = np.matmul(graph.F.cpu().numpy(), corner_coords)[0]\n",
    "            # new_corners = ax.scatter(*corner_coords, marker='x', label='new corners', c='red', s=20)\n",
    "            ax.fill(*corner_coords, facecolor='lightgray')\n",
    "\n",
    "            if i == 0:  # first model\n",
    "                ax.set_title(f'{key}', size=16)\n",
    "            if j == 0:  # first test case\n",
    "                ax.set_ylabel(f'{name}', size=16)\n",
    "\n",
    "            # make plot square\n",
    "            xlims = ax.get_xlim()\n",
    "            ylims = ax.get_ylim()\n",
    "            low = min(xlims[0], ylims[0])\n",
    "            high = max(xlims[1], ylims[1])\n",
    "            ax.set_xlim([low, high])\n",
    "            ax.set_ylim([low, high])\n",
    "\n",
    "            # ax.set_title(f'F={graph.F.detach().numpy()[0]}')\n",
    "            # F_temp = graph.F.detach().cpu().numpy()[0]\n",
    "            # temp_str = r'$\\textbf{\\textrm{F}}=\\begin{bmatrix}' + str(F_temp[0,0]) + ' & ' + str(F_temp[0, 1]) + r'\\\\' + str(F_temp[1, 0]) + ' & ' + str(F_temp[1, 1]) + r'\\end{bmatrix}$'\n",
    "            # ax.set_title(temp_str)\n",
    "\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "for fig, ind in zip(figs, inds_to_plot):\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "    # fig.suptitle(f'{F[ind]}')\n",
    "    path = f'results/final_results/compare_deformations2_F=[{F[ind][0]},{F[ind][1]}]'\n",
    "    path.replace(' ', '_')\n",
    "    fig.savefig(path + '.svg')\n",
    "    fig.savefig(path + '.pdf')\n",
    "    fig.savefig(path + '.png')\n",
    "\n",
    "plt.close('all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spider plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Define spider plots\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarTransform(PolarAxes.PolarTransform):\n",
    "\n",
    "        def transform_path_non_affine(self, path):\n",
    "            # Paths with non-unit interpolation steps correspond to gridlines,\n",
    "            # in which case we force interpolation (to defeat PolarTransform's\n",
    "            # autoconversion to circular arcs).\n",
    "            if path._interpolation_steps > 1:\n",
    "                path = path.interpolated(num_vars)\n",
    "            return Path(self.transform(path.vertices), path.codes)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        PolarTransform = RadarTransform\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define quantities for spider plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'FVU' # 'MSE' #\n",
    "\n",
    "if (metric == 'FVU' or metric == 'R2'):\n",
    "    with open('results/final_results/results_R2_4.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "elif metric == 'MSE':\n",
    "    with open('results/final_results/results_MSE_4.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "else:\n",
    "    raise ValueError(f'{metric} is an invalid metric')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    'text.latex.preamble': r'\\usepackage{{amsmath}} \\usepackage{{amssymb}}',\n",
    "    # 'font.size': 14\n",
    "})\n",
    "spoke_quantities= ['reference', 'scaled', 'rotated',\n",
    "                'reflected', 'larger RVE', 'shifted RVE']\n",
    "spoke_labels = ['reference', 'scaled', 'rotated',\n",
    "                'reflected', 'extended RVE', 'shifted RVE']\n",
    "quantities = ['y', 'W', 'P', 'D']\n",
    "models = ['GNN',\n",
    "          'GNN, DA ×1', 'GNN, DA ×2',\n",
    "         'EGNN',\n",
    "         'EGNN, DA ×1', 'EGNN, DA ×2',\n",
    "          'SimEGNN']\n",
    "colors = ['tab:blue',\n",
    "          'tab:blue', 'tab:blue',\n",
    "          'tab:orange',\n",
    "          'tab:orange', 'tab:orange',\n",
    "          'tab:green']\n",
    "linestyles = ['solid',\n",
    "              'dashed', 'dotted',\n",
    "              'solid',\n",
    "              'dashed', 'dotted',\n",
    "              'solid']\n",
    "\n",
    "model_names = models  #['GNN', 'GNN, Data Augmentation', 'Improved GNN']\n",
    "\n",
    "N = len(spoke_labels)\n",
    "theta = radar_factory(N, frame='polygon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spider plots (2×2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# fig, axs = plt.subplots(figsize=(9, 9), nrows=2, ncols=2,\n",
    "#                         subplot_kw=dict(projection='radar'))\n",
    "# fig.subplots_adjust(wspace=0.35, hspace=0.30, top=0.85, bottom=0.05)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(7, 7), nrows=2, ncols=2,\n",
    "                        subplot_kw=dict(projection='radar'), frameon=False)\n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.4, top=0.85, bottom=0.05, left=0.03, right=0.95)\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "# colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "# Plot the four cases from the example data on separate axes\n",
    "for ax, quantity, title in zip(axs.flat, quantities,\n",
    "                               [r'microfluctuation $\\vec{w}$',\n",
    "                                r'energy $\\mathfrak{W}$',\n",
    "                                r'stress $\\textbf{\\textrm{P}}$',\n",
    "                                r'stiffness $\\textbf{\\textrm{D}}$'\n",
    "                                ]):\n",
    "    # ax.set_rgrids([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_title(title, weight='bold', size='large', position=(0.5, 1.3),\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    for model, color, linestyle in zip(models, colors, linestyles):\n",
    "        if metric == 'FVU':\n",
    "            r = [1-results[model][key][quantity] for key in spoke_quantities]\n",
    "        else:\n",
    "            r = [results[model][key][quantity] for key in spoke_quantities]\n",
    "        ax.plot(theta, r, color=color, linestyle=linestyle)\n",
    "        # ax.fill(theta, results2[quantity][key], facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    if metric == 'FVU':\n",
    "        if quantity == 'D':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-5, 1e-1])\n",
    "        elif quantity == 'W':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-2])\n",
    "        elif quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-2, 1])\n",
    "        else:\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-3])\n",
    "    elif metric == 'MSE':\n",
    "        if quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "        elif quantity == 'P':\n",
    "            ax.set_rscale('symlog', linthresh=1e-2)\n",
    "        else:\n",
    "            ax.set_rscale('symlog')\n",
    "    else:\n",
    "        raise NotImplementedError(f'metric {metric} not implemented')\n",
    "    # ax.set_rasterization_zorder(1)\n",
    "\n",
    "    labels = ax.get_yticklabels()\n",
    "    for label in labels:\n",
    "        label.set_x(-0.39)  # Adjust the x-position\n",
    "        # print(*label.get_position(), label.get_text())\n",
    "\n",
    "\n",
    "    # # Adjust the labelpad property for each tick label\n",
    "    # for label in labels:\n",
    "    #     label.set_bbox(dict(facecolor='white', edgecolor='none', pad=2.0))  # Optional: Add a white background\n",
    "    #     label.set_horizontalalignment('center')  # Optional: Center-align the labels\n",
    "    #     label.set_verticalalignment('center')    # Optional: Center-align the labels\n",
    "    #     # label.set_rotation(180 * label.get_position()[0] / np.pi - 90)  # Optional: Rotate the labels\n",
    "    #     # label.set_pad(5)  # Adjust the labelpad to move labels inwards\n",
    "\n",
    "# add legend relative to top-left plot\n",
    "legend = axs[0, 0].legend(model_names, loc=(0.9, .95),\n",
    "                            labelspacing=0.1,\n",
    "                            fontsize='small'\n",
    "                        )\n",
    "\n",
    "# fig.text(0.5, 0.965, '5-Factor Solution Profiles Across Four Scenarios',\n",
    "#             horizontalalignment='center', color='black', weight='bold',\n",
    "#             size='large')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'results/final_results/spiderplots_{metric}.pdf')\n",
    "fig.savefig(f'results/final_results/spiderplots_{metric}.png', dpi=600)\n",
    "fig.savefig(f'results/final_results/spiderplots_{metric}.svg' )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spider plots (4×1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "spoke_labels = 6*['']\n",
    "# fig, axs = plt.subplots(figsize=(9, 9), nrows=2, ncols=2,\n",
    "#                         subplot_kw=dict(projection='radar'))\n",
    "# fig.subplots_adjust(wspace=0.35, hspace=0.30, top=0.85, bottom=0.05)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 4), nrows=1, ncols=4,\n",
    "                        subplot_kw=dict(projection='radar'))\n",
    "fig.subplots_adjust(wspace=0.4, hspace=0.40, top=0.85, bottom=0.05)\n",
    "fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "# colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "# Plot the four cases from the example data on separate axes\n",
    "for ax, quantity, title in zip(axs.flat, quantities,\n",
    "                               [r'position $\\vec{x}$' if metric=='MSE' else\n",
    "                                r'microfluctuation $\\vec{w}$',\n",
    "                                r'energy $\\mathfrak{W}$',\n",
    "                                r'stress $\\textbf{\\textrm{P}}$',\n",
    "                                r'stiffness $\\textbf{\\textrm{D}}$'\n",
    "                                ]):\n",
    "    # ax.set_rgrids([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_title(title, weight='bold', size='large', y=1.35, pad=-14,\n",
    "                 #position=(0.5, 1.3),\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    for model, color, linestyle, alpha in zip(models, colors, linestyles, [1, 1, 0]):\n",
    "        if metric == 'FVU':\n",
    "            r = [1-results[model][key][quantity] for key in spoke_quantities]\n",
    "        else:\n",
    "            r = [results[model][key][quantity] for key in spoke_quantities]\n",
    "        ax.plot(theta, r, color=color, linestyle=linestyle, alpha=alpha)\n",
    "        # ax.fill(theta, results2[quantity][key], facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    if metric == 'FVU':\n",
    "        if quantity == 'D':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-5, 1e-1])\n",
    "        elif quantity == 'W':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-2])\n",
    "        elif quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-2, 1])\n",
    "        else:\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-3])\n",
    "    elif metric == 'MSE':\n",
    "        if quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "        elif quantity == 'P':\n",
    "            ax.set_rscale('symlog', linthresh=1e-2)\n",
    "        else:\n",
    "            ax.set_rscale('symlog')\n",
    "    else:\n",
    "        raise NotImplementedError(f'metric {metric} not implemented')\n",
    "    # ax.set_rasterization_zorder(1)\n",
    "\n",
    "    labels = ax.get_yticklabels()\n",
    "\n",
    "    # # Adjust the labelpad property for each tick label\n",
    "    # for label in labels:\n",
    "    #     label.set_bbox(dict(facecolor='white', edgecolor='none', pad=2.0))  # Optional: Add a white background\n",
    "    #     label.set_horizontalalignment('center')  # Optional: Center-align the labels\n",
    "    #     label.set_verticalalignment('center')    # Optional: Center-align the labels\n",
    "    #     # label.set_rotation(180 * label.get_position()[0] / np.pi - 90)  # Optional: Rotate the labels\n",
    "    #     # label.set_pad(5)  # Adjust the labelpad to move labels inwards\n",
    "\n",
    "    # Adjust the position of the tick labels\n",
    "    labelpad = 5  # Set the desired padding value\n",
    "    for label in labels:\n",
    "        label.set_x(-0.39)  # Adjust the x-position\n",
    "        # label.set_y(label.get_position()[1] - 500)  # Keep the y-position unchanged\n",
    "\n",
    "# add legend relative to top-left plot\n",
    "legend = axs[0].legend(model_names, loc=(0.9, .95),\n",
    "                            labelspacing=0.1,\n",
    "                            fontsize='small'\n",
    "                        )\n",
    "\n",
    "# fig.text(0.5, 0.965, '5-Factor Solution Profiles Across Four Scenarios',\n",
    "#             horizontalalignment='center', color='black', weight='bold',\n",
    "#             size='large')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'results/final_results/spiderplots1×4_{metric}_3.pdf')\n",
    "fig.savefig(f'results/final_results/spiderplots1×4_{metric}_3.png', dpi=600)\n",
    "fig.savefig(f'results/final_results/spiderplots1×4_{metric}_3.svg' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spider plots (2×1), models appear one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "spoke_labels = 6*['']\n",
    "# fig, axs = plt.subplots(figsize=(9, 9), nrows=2, ncols=2,\n",
    "#                         subplot_kw=dict(projection='radar'))\n",
    "# fig.subplots_adjust(wspace=0.35, hspace=0.30, top=0.85, bottom=0.05)\n",
    "\n",
    "for i in range(3):\n",
    "    fig, axs = plt.subplots(figsize=(6, 4), nrows=1, ncols=2,\n",
    "                            subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.3, hspace=0.40, top=0.85, bottom=0.05)\n",
    "    fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "    # colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "    # Plot the four cases from the example data on separate axes\n",
    "    for ax, quantity, title in zip(axs.flat, quantities[2:],\n",
    "                                [\n",
    "                                    #r'position $\\vec{x}$' if metric=='MSE' else\n",
    "                                    # r'microfluctuation $\\vec{w}$',\n",
    "                                    # r'energy $\\mathfrak{W}$',\n",
    "                                    r'stress $\\textbf{\\textrm{P}}$',\n",
    "                                    r'stiffness $\\textbf{\\textrm{D}}$'\n",
    "                                    ]):\n",
    "        # ax.set_rgrids([0.2, 0.4, 0.6, 0.8])\n",
    "        ax.set_title(title, weight='bold', size='large', y=1.35, pad=-14,\n",
    "                    #position=(0.5, 1.3),\n",
    "                        horizontalalignment='center', verticalalignment='center')\n",
    "        alphas = [1]*(i+1) + [0]*(2-i)\n",
    "        for model, color, linestyle, alpha in zip(models, colors, linestyles, alphas):\n",
    "            if metric == 'FVU':\n",
    "                r = [1-results[model][key][quantity] for key in spoke_quantities]\n",
    "            else:\n",
    "                r = [results[model][key][quantity] for key in spoke_quantities]\n",
    "            ax.plot(theta, r, color=color, linestyle=linestyle, alpha=alpha)\n",
    "            # ax.fill(theta, results2[quantity][key], facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "        ax.set_varlabels(spoke_labels)\n",
    "\n",
    "        if metric == 'FVU':\n",
    "            if quantity == 'D':\n",
    "                ax.set_rscale('symlog', linthresh=1e-4)\n",
    "                # ax.set_rlim([1e-5, 1e-1])\n",
    "            elif quantity == 'W':\n",
    "                ax.set_rscale('symlog', linthresh=1e-6)\n",
    "                # ax.set_rlim([1e-7, 1e-2])\n",
    "            elif quantity == 'y':\n",
    "                ax.set_rscale('symlog', linthresh=1e-4)\n",
    "                # ax.set_rlim([1e-2, 1])\n",
    "            else:\n",
    "                ax.set_rscale('symlog', linthresh=1e-6)\n",
    "                # ax.set_rlim([1e-7, 1e-3])\n",
    "        elif metric == 'MSE':\n",
    "            if quantity == 'y':\n",
    "                ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            elif quantity == 'P':\n",
    "                ax.set_rscale('symlog', linthresh=1e-2)\n",
    "            else:\n",
    "                ax.set_rscale('symlog')\n",
    "        else:\n",
    "            raise NotImplementedError(f'metric {metric} not implemented')\n",
    "        # ax.set_rasterization_zorder(1)\n",
    "\n",
    "        labels = ax.get_yticklabels()\n",
    "\n",
    "        # # Adjust the labelpad property for each tick label\n",
    "        # for label in labels:\n",
    "        #     label.set_bbox(dict(facecolor='white', edgecolor='none', pad=2.0))  # Optional: Add a white background\n",
    "        #     label.set_horizontalalignment('center')  # Optional: Center-align the labels\n",
    "        #     label.set_verticalalignment('center')    # Optional: Center-align the labels\n",
    "        #     # label.set_rotation(180 * label.get_position()[0] / np.pi - 90)  # Optional: Rotate the labels\n",
    "        #     # label.set_pad(5)  # Adjust the labelpad to move labels inwards\n",
    "\n",
    "        # Adjust the position of the tick labels\n",
    "        labelpad = 5  # Set the desired padding value\n",
    "        for label in labels:\n",
    "            label.set_x(-0.39)  # Adjust the x-position\n",
    "            # label.set_y(label.get_position()[1] - 500)  # Keep the y-position unchanged\n",
    "\n",
    "    # # add legend relative to top-left plot\n",
    "    # legend = axs[0].legend(model_names, loc=(0.9, .95),\n",
    "    #                             labelspacing=0.1,\n",
    "    #                             fontsize='small'\n",
    "    #                         )\n",
    "\n",
    "    # fig.text(0.5, 0.965, '5-Factor Solution Profiles Across Four Scenarios',\n",
    "    #             horizontalalignment='center', color='black', weight='bold',\n",
    "    #             size='large')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f'results/final_results/spiderplots1×2_{metric}_{i}.pdf')\n",
    "    fig.savefig(f'results/final_results/spiderplots1×2_{metric}_{i}.png', dpi=600)\n",
    "    fig.savefig(f'results/final_results/spiderplots1×2_{metric}_{i}.svg' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create spider plots (1 figure per target quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# fig, axs = plt.subplots(figsize=(9, 9), nrows=2, ncols=2,\n",
    "#                         subplot_kw=dict(projection='radar'))\n",
    "# fig.subplots_adjust(wspace=0.35, hspace=0.30, top=0.85, bottom=0.05)\n",
    "\n",
    "\n",
    "\n",
    "# colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "# Plot the four cases from the example data on separate axes\n",
    "for i, [quantity, title, short_title] in enumerate(zip(quantities,\n",
    "                               [r'microfluctuation $\\vec{w}$',\n",
    "                                r'energy $\\mathfrak{W}$',\n",
    "                                r'stress $\\textbf{\\textrm{P}}$',\n",
    "                                r'stiffness $\\textbf{\\textrm{D}}$'\n",
    "                                ],\n",
    "                                ['w', 'W', 'P', 'D'])):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,4),\n",
    "                        subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.4, hspace=0.40, top=0.8, bottom=0.1, left=0.3, right=0.7)\n",
    "    fig.patch.set_facecolor(\"None\")\n",
    "\n",
    "    # ax.set_rgrids([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_title(title, weight='bold', size='large', position=(0.5, 1.3),\n",
    "                    horizontalalignment='center', verticalalignment='center')\n",
    "    for model, color, linestyle in zip(models, colors, linestyles):\n",
    "        if metric == 'FVU':\n",
    "            r = [1-results[model][key][quantity] for key in spoke_quantities]\n",
    "        else:\n",
    "            r = [results[model][key][quantity] for key in spoke_quantities]\n",
    "        ax.plot(theta, r, color=color, linestyle=linestyle)\n",
    "        # ax.fill(theta, results2[quantity][key], facecolor=color, alpha=0.25, label='_nolegend_')\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    if metric == 'FVU':\n",
    "        if quantity == 'D':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-5, 1e-1])\n",
    "        elif quantity == 'W':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-2])\n",
    "        elif quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-4)\n",
    "            # ax.set_rlim([1e-2, 1])\n",
    "        else:\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "            # ax.set_rlim([1e-7, 1e-3])\n",
    "    elif metric == 'MSE':\n",
    "        if quantity == 'y':\n",
    "            ax.set_rscale('symlog', linthresh=1e-6)\n",
    "        elif quantity == 'P':\n",
    "            ax.set_rscale('symlog', linthresh=1e-2)\n",
    "        else:\n",
    "            ax.set_rscale('symlog')\n",
    "    else:\n",
    "        raise NotImplementedError(f'metric {metric} not implemented')\n",
    "    # ax.set_rasterization_zorder(1)\n",
    "\n",
    "    labels = ax.get_yticklabels()\n",
    "\n",
    "    # # Adjust the labelpad property for each tick label\n",
    "    # for label in labels:\n",
    "    #     label.set_bbox(dict(facecolor='white', edgecolor='none', pad=2.0))  # Optional: Add a white background\n",
    "    #     label.set_horizontalalignment('center')  # Optional: Center-align the labels\n",
    "    #     label.set_verticalalignment('center')    # Optional: Center-align the labels\n",
    "    #     # label.set_rotation(180 * label.get_position()[0] / np.pi - 90)  # Optional: Rotate the labels\n",
    "    #     # label.set_pad(5)  # Adjust the labelpad to move labels inwards\n",
    "\n",
    "    # Adjust the position of the tick labels\n",
    "    labelpad = 5  # Set the desired padding value\n",
    "    for label in labels:\n",
    "        label.set_x(-0.39)  # Adjust the x-position\n",
    "        # label.set_y(label.get_position()[1] - 500)  # Keep the y-position unchanged\n",
    "\n",
    "    if i == 0:\n",
    "        # add legend relative to top-left plot\n",
    "        legend = ax.legend(model_names, loc=(0.87, .95),\n",
    "                                    labelspacing=0.1,\n",
    "                                    fontsize='small'\n",
    "                                )\n",
    "\n",
    "# fig.text(0.5, 0.965, '5-Factor Solution Profiles Across Four Scenarios',\n",
    "#             horizontalalignment='center', color='black', weight='bold',\n",
    "#             size='large')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig.savefig(f'results/final_results/spiderplots_{metric}_{short_title}.pdf')\n",
    "    fig.savefig(f'results/final_results/spiderplots_{metric}_{short_title}.png', dpi=600)\n",
    "    fig.savefig(f'results/final_results/spiderplots_{metric}_{short_title}.svg' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX table MSE/FVU/R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metric = 'MSE'\n",
    "\n",
    "if (metric == 'FVU' or metric == 'R2'):\n",
    "    with open('results/final_results/results_R2_4.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "elif metric == 'MSE':\n",
    "    with open('results/final_results/results_MSE_4.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)\n",
    "else:\n",
    "    raise ValueError(f'{metric} is an invalid metric')\n",
    "\n",
    "results2 = {}\n",
    "for model in results:\n",
    "    for key in results[model]:\n",
    "        for var in results[model][key]:\n",
    "            if var not in results2:\n",
    "                results2[var] = {}\n",
    "            if model not in results2[var]:\n",
    "                results2[var][model] = []\n",
    "\n",
    "            if metric == 'FVU':\n",
    "                results2[var][model].append(1-results[model][key][var])\n",
    "            else:\n",
    "                results2[var][model].append(results[model][key][var])\n",
    "\n",
    "# %%\n",
    "def formatter(number):\n",
    "    string = f'{number:.1e}'\n",
    "    if string.startswith('-'):\n",
    "        sign = '-'\n",
    "        string = string[1:]\n",
    "    else:\n",
    "        sign = ''\n",
    "    mantissa, exponent = string.split('e')\n",
    "    if exponent.startswith('+'):\n",
    "        exponent = exponent[1:]\n",
    "    exponent = int(exponent)\n",
    "    if -3 <= exponent <= 2:\n",
    "        string2 = f'${np.format_float_positional(number, precision=2, fractional=False, unique=False)}$'\n",
    "    else:\n",
    "        string2 = f'${sign}{mantissa}\\times 10^{{{exponent}}}$'\n",
    "    return string2\n",
    "\n",
    "testcase_names = ['reference', 'noisy distances', 'shifted RVE', 'extended RVE', 'reflected', 'rotated', 'scaled']  #, 'diameter 0.8 (unbuckled)', 'diameter 0.8 (buckled)', 'finer mesh']\n",
    "\n",
    "model_names = ['GNN',\n",
    "         'GNN, DA ×1',\n",
    "         'GNN, DA ×2',\n",
    "         'EGNN',\n",
    "         'EGNN, DA ×1',\n",
    "         'EGNN, DA ×2',\n",
    "         'SimEGNN',\n",
    "        #  'EGNNmod2_bigger'\n",
    "        ]\n",
    "\n",
    "print(r'\\begin{table}')\n",
    "for var, symbol, name in zip(['y', 'W', 'P', 'D'],\n",
    "                               [r'$\\vec{w}$',\n",
    "                                r'$\\mathfrak{W}$',\n",
    "                                r'$\\textbf{\\textrm{P}}$',\n",
    "                                r'$\\textbf{\\textrm{D}}$'\n",
    "                                ],\n",
    "                             ['microfluctuation', 'strain energy density', 'first Piola-Kirchhoff stress tensor',\n",
    "                              'stiffness tensor']):\n",
    "\n",
    "    df = pd.DataFrame(results2[var], index = results['GNN'].keys())\n",
    "\n",
    "    # shuffle the rows to the order I want\n",
    "    df = df.loc[testcase_names]\n",
    "\n",
    "    # rename the columns\n",
    "    df.columns = model_names\n",
    "\n",
    "    # find best result per row\n",
    "    inds = np.argmin(df.values, axis=1)\n",
    "\n",
    "    # apply formatting\n",
    "    df = df.applymap(formatter)\n",
    "\n",
    "    # make best result per row boldface\n",
    "    for i, ind in enumerate(inds):\n",
    "        df.iloc[i, ind] = '$\\mathbf{' + df.iloc[i, ind][1:-1] + '}$'\n",
    "\n",
    "    print(r'\\centering')\n",
    "    print(r'\\tiny')\n",
    "    print(r'\\caption{', metric, ' of the ', f'{name} {symbol}', r'\\label{tab:results', var, '}}', sep='')\n",
    "    print(df.to_latex(escape=False))\n",
    "    print(r'\\bigskip')\n",
    "    print('')\n",
    "\n",
    "print(r'\\end{table}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX table frob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('results/final_results/results_frob.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "results2 = {}\n",
    "for model in results:\n",
    "    for key in results[model]:\n",
    "        for var in results[model][key]:\n",
    "            if var not in results2:\n",
    "                results2[var] = {}\n",
    "            if model not in results2[var]:\n",
    "                results2[var][model] = []\n",
    "\n",
    "            results2[var][model].append(results[model][key][var])\n",
    "\n",
    "# %%\n",
    "def formatter(number):\n",
    "    string = np.format_float_positional(number*100, precision=2, fractional=False, unique=False)\n",
    "    return f'${string}\\%$'\n",
    "\n",
    "testcase_names = ['reference', #'noisy distances',\n",
    "                  'shifted RVE', 'extended RVE', 'reflected', 'rotated', 'scaled']  #, 'diameter 0.8 (unbuckled)', 'diameter 0.8 (buckled)', 'finer mesh']\n",
    "\n",
    "model_names = ['GNN',\n",
    "         'GNN, DA ×1',\n",
    "         'GNN, DA ×2',\n",
    "         'EGNN',\n",
    "         'EGNN, DA ×1',\n",
    "         'EGNN, DA ×2',\n",
    "         'SimEGNN',\n",
    "        #  'EGNNmod2_bigger'\n",
    "        ]\n",
    "\n",
    "print(r'\\begin{table}')\n",
    "for var, symbol, name in zip(['y', 'W', 'P', 'D'],\n",
    "                               [r'$\\vec{w}$',\n",
    "                                r'$\\mathfrak{W}$',\n",
    "                                r'$\\textbf{\\textrm{P}}$',\n",
    "                                r'$\\textbf{\\textrm{D}}$'\n",
    "                                ],\n",
    "                             ['microfluctuation', 'strain energy density', 'first Piola-Kirchhoff stress tensor',\n",
    "                              'stiffness tensor']):\n",
    "\n",
    "    df = pd.DataFrame(results2[var], index = results['GNN'].keys())\n",
    "\n",
    "    # shuffle the rows to the order I want\n",
    "    df = df.loc[testcase_names]\n",
    "\n",
    "    # rename the columns\n",
    "    df.columns = model_names\n",
    "\n",
    "    # find best result per row\n",
    "    inds = np.argmin(df.values, axis=1)\n",
    "\n",
    "    # apply formatting\n",
    "    df = df.applymap(formatter)\n",
    "\n",
    "    # make best result per row boldface\n",
    "    for i, ind in enumerate(inds):\n",
    "        df.iloc[i, ind] = '$\\mathbf{' + df.iloc[i, ind][1:-3] + '}\\%$'\n",
    "\n",
    "    print(r'\\centering')\n",
    "    print(r'\\tiny')\n",
    "    print(r'\\caption{Relative error of the ', f'{name} {symbol}', r'\\label{tab:resultsfrob', var, '}}', sep='')\n",
    "    print(df.to_latex(escape=False))\n",
    "    print(r'\\bigskip')\n",
    "    print('')\n",
    "\n",
    "print(r'\\end{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
