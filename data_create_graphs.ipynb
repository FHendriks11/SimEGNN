{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries, define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch_geometric as tg\n",
    "\n",
    "import funcs_helpers as fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 0.9\n",
    "\n",
    "# path to get DataFrame\n",
    "df_path = f\"data\\\\coarseMesh_noBifurcation_5\\\\dataframe_coarseMesh_noBifurcation_diameter_{diameter}_5.pkl\"\n",
    "\n",
    "# path to put graph data\n",
    "gr_path = f'data\\\\coarseMesh_noBifurcation_5\\\\graphs_coarseMesh_noBifurcation_diameter_{diameter}_5_noBulkNodes_4.pkl'\n",
    "# f'data\\\\coarseMesh\\\\graphs_coarseMesh_diameter_{diameter}_fixed.pkl'\n",
    "\n",
    "mesh_path = mesh_path = r\"data\\coarseMesh_noBifurcation_5\\mesh_info.mat\"\n",
    "\n",
    "# whether the mesh (connectivity AND initial node positions!) is always the same or if it varies per trajectory\n",
    "constant_mesh = True #  False  #\n",
    "\n",
    "remove_bulk_nodes = True #False\n",
    "\n",
    "if not constant_mesh:\n",
    "    raise NotImplementedError('non-constant mesh not implemented')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_path, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('df.shape before:', df.shape)\n",
    "W = np.array(df['W'])\n",
    "bools = np.isnan(W)\n",
    "print(sum(bools), 'cases where W is NaN')\n",
    "df = df[~bools]\n",
    "print('df.shape after:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicate F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique F\n",
    "F = np.stack(df['F'], axis=0)\n",
    "print('F.shape:', F.shape)\n",
    "unique_F, inds_to_keep = np.unique(F, return_index=True, axis=0)\n",
    "print('unique_F.shape:', unique_F.shape)\n",
    "\n",
    "print('df.shape before:', df.shape)\n",
    "df = df.iloc[inds_to_keep]\n",
    "print('df.shape after:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_path + '_reduced2.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(df_path + '_reduced2.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to store data associated with edges\n",
    "e_data = {}\n",
    "\n",
    "# dict to store data associated with nodes\n",
    "n_data = {}\n",
    "\n",
    "# dict to store any indices into the edges\n",
    "e_inds = {}\n",
    "\n",
    "# dict to store any indices into the nodes\n",
    "n_inds = {}\n",
    "\n",
    "# dict to store graph-level data\n",
    "g_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import one mesh (everything except position is the same for all meshes)\n",
    "file = mesh_path\n",
    "mesh_vars = loadmat(file)\n",
    "\n",
    "# # check which mesh variables there are\n",
    "for key in mesh_vars:\n",
    "    print(key)\n",
    "\n",
    "if constant_mesh:\n",
    "    n_data['pos'] = mesh_vars['p']\n",
    "else:\n",
    "    n_data['pos'] = np.stack(df['pos'].values)\n",
    "\n",
    "# triangle definitions\n",
    "n_inds['t'] = mesh_vars['t'].astype(int)-1\n",
    "\n",
    "# indices of boundary nodes (-1 because of matlab indexing)\n",
    "n_inds['b_bottom'] = mesh_vars['IDGamma_1'][0]-1\n",
    "n_inds['b_right'] = mesh_vars['IDGamma_2'][0]-1\n",
    "n_inds['b_top'] = mesh_vars['IDGamma_3'][0]-1\n",
    "n_inds['b_left'] = mesh_vars['IDGamma_4'][0]-1\n",
    "\n",
    "# indices of corner nodes\n",
    "n_inds['dependent_corner_inds'] = np.asarray([mesh_vars[key][0,0]-1 for key in\n",
    "    ['id2', 'id3', 'id4']])\n",
    "n_inds['fixed_corner_ind'] = mesh_vars['id1'][0,0]-1\n",
    "\n",
    "# indices of hole boundary nodes\n",
    "# n_inds['hole_boundary'] = mesh_vars['hole_boundaries']-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # extract boundary nodes\n",
    "tol_g = 1e-6\n",
    "x_min, x_max = np.min(n_data['pos'][0]), np.max(n_data['pos'][0])\n",
    "y_min, y_max = np.min(n_data['pos'][1]), np.max(n_data['pos'][1])\n",
    "n_inds['b_bottom'] = np.where(n_data['pos'][1] < y_min + tol_g)[0]\n",
    "n_inds['b_right'] = np.where(n_data['pos'][0] > x_max - tol_g)[0]\n",
    "n_inds['b_top'] = np.where(n_data['pos'][1] > y_max - tol_g)[0]\n",
    "n_inds['b_left'] = np.where(n_data['pos'][0] < x_min + tol_g)[0]\n",
    "\n",
    "# sort indices\n",
    "n_inds['b_bottom'] = n_inds['b_bottom'][np.argsort(n_data['pos'][0][n_inds['b_bottom']])]\n",
    "n_inds['b_right'] = n_inds['b_right'][np.argsort(n_data['pos'][1][n_inds['b_right']])]\n",
    "n_inds['b_top'] = n_inds['b_top'][np.argsort(n_data['pos'][0][n_inds['b_top']])]\n",
    "n_inds['b_left'] = n_inds['b_left'][np.argsort(n_data['pos'][1][n_inds['b_left']])]\n",
    "\n",
    "# extract dependent corner nodes\n",
    "n_inds['dependent_corner_inds'] = np.array([\n",
    "    np.where((n_data['pos'][1] < y_min + tol_g)*(n_data['pos'][0] > x_max - tol_g))[0][0],\n",
    "    np.where((n_data['pos'][1] > y_max - tol_g)*(n_data['pos'][0] > x_max - tol_g))[0][0],\n",
    "    np.where((n_data['pos'][1] > y_max - tol_g)*(n_data['pos'][0] < x_min + tol_g))[0][0],\n",
    "])\n",
    "\n",
    "# extract independent corner node\n",
    "n_inds['fixed_corner_ind'] = np.where((n_data['pos'][1] < y_min + tol_g)*(n_data['pos'][0] < x_min + tol_g))[0][0]\n",
    "\n",
    "print(n_inds['fixed_corner_ind'])\n",
    "print(n_inds['dependent_corner_inds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all other data from df to dicts\n",
    "n_data['U_arr'] = np.array([np.reshape(elem, (-1, 2)).T for elem in df['U']])\n",
    "\n",
    "# put FE results in the right shape to compare them (and convert from Matlabs column-major order)\n",
    "g_data['F'] = np.stack(df['F'])\n",
    "g_data['W'] = df['W'].values[..., np.newaxis]\n",
    "g_data['P'] = np.stack(df['P'].values, axis=0)[:, [0, 2, 1, 3]].reshape(-1, 2, 2)\n",
    "g_data['D'] = np.stack(df['D'].values, axis=0)\n",
    "g_data['traj'] = df['trajectory'].values[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in g_data:\n",
    "    print(f'{key:10} {g_data[key].shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges\n",
    "Turn triangles (quadratic elements) into edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all nodes of the quadratic elements or only the corner nodes\n",
    "corner_nodes_only = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triangles are described by first their corner nodes, then the nodes in the middle of the sides\n",
    "\n",
    "if corner_nodes_only:\n",
    "    # use only corner nodes\n",
    "    inds = ([[0, 1, 2],\n",
    "            [1, 2, 0]],)\n",
    "else:\n",
    "    # use all nodes\n",
    "    inds = ([[0, 3, 1, 4, 2, 5],\n",
    "            [3, 1, 4, 2, 5, 0]],)\n",
    "\n",
    "edge_index = n_inds['t'][inds].reshape(2, -1)\n",
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort such that edge 0->1 is the same as 1->0\n",
    "edge_index = np.sort(edge_index, axis=0)\n",
    "\n",
    "# remove duplicate edges\n",
    "print(edge_index.shape)\n",
    "edge_index, counts = np.unique(edge_index, axis=1, return_counts=True)\n",
    "print(edge_index.shape)\n",
    "\n",
    "# index into edge_index of edges at boundaries (sides or holes)\n",
    "# (edges at boundaries are in only one element so their count=1)\n",
    "e_inds['all_boundaries'] = np.where(counts == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these now instead of earlier, because they should not be considered boundary edges, even though they are in only one element\n",
    "if not corner_nodes_only:\n",
    "    # add edge_index between mid-side nodes\n",
    "    inds = ([[3,4,5],\n",
    "            [4,5,3]],)\n",
    "\n",
    "    edge_index2 = n_inds['t'][inds].reshape(2, -1)\n",
    "    print(edge_index.shape)\n",
    "    print(edge_index2.shape)\n",
    "    edge_index = np.concatenate((edge_index, edge_index2), axis=-1)\n",
    "    print(edge_index.shape)\n",
    "\n",
    "e_data['edge_index'] = edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot mesh to check\n",
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "if constant_mesh:\n",
    "    pos_temp = n_data['pos']\n",
    "    edge_index_temp = e_data['edge_index']\n",
    "else:\n",
    "    pos_temp = n_data['pos'][0]\n",
    "    edge_index_temp = e_data['edge_index'][0]\n",
    "plt.scatter(*pos_temp, c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "x, y = pos_temp.T[edge_index_temp].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='black', alpha=0.3, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.sort(e_data['edge_index'], axis=0), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data['edge_index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data['pos'].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep nodes that are in edge_index, remove other nodes, relabel edges\n",
    "# (only makes a difference when only using corner nodes, then mid-edge nodes are removed)\n",
    "nodes_to_keep, edge_index = np.unique(e_data['edge_index'], return_inverse=True)\n",
    "edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "for key in n_inds:\n",
    "    # find index into nodes_to_keep of the nodes in n_inds\n",
    "    temp = np.searchsorted(nodes_to_keep, n_inds[key])\n",
    "\n",
    "    # keep only the ones that are in nodes_to_keep\n",
    "    n_inds[key] = n_inds[key][n_inds[key] == nodes_to_keep[temp]]\n",
    "\n",
    "for key in n_data:\n",
    "    n_data[key] = n_data[key][..., nodes_to_keep]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate positions (original, affine, final) and displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions of nodes after affine transformation\n",
    "n_data['pos_affine'] = np.matmul(g_data['F'], n_data['pos'])\n",
    "\n",
    "# original vectors along edges\n",
    "e_data['r'] = n_data['pos'][..., e_data['edge_index'][1]] - n_data['pos'][..., e_data['edge_index'][0]]\n",
    "\n",
    "# vectors along edges after affine transformation\n",
    "# e_data['r_affine'] = n_data['pos_affine'][..., e_data['edge_index'][1]] - n_data['pos_affine'][..., e_data['edge_index'][0]]\n",
    "\n",
    "# length of edges\n",
    "e_data['d'] = np.linalg.norm(e_data['r'], axis=-2)\n",
    "# e_data['d_affine'] = np.linalg.norm(e_data['r_affine'], axis=-2)\n",
    "\n",
    "# final position of nodes\n",
    "n_data['pos_final'] = n_data['pos']+ n_data['U_arr']\n",
    "\n",
    "# # affine displacement of nodes\n",
    "# n_data['U_affine'] = n_data['pos_affine'] - n_data['pos']\n",
    "\n",
    "# # periodic displacement of nodes\n",
    "# n_data['w'] = n_data['U_arr'] - n_data['U_affine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot meshes\n",
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "plt.scatter(*(n_data['pos']), c='tab:blue', s=1)\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='tab:blue', alpha=0.3, zorder=-1)\n",
    "\n",
    "\n",
    "# plot all nodes in affine location\n",
    "plt.scatter(*(n_data['pos_affine'][0]), c='tab:orange', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos_affine'][0].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='tab:orange', alpha=0.3, zorder=-1)\n",
    "\n",
    "\n",
    "# plot all nodes in final location\n",
    "plt.scatter(*(n_data['pos_final'][0]), c='tab:green', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos_final'][0].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='tab:green', alpha=0.3, zorder=-1)\n",
    "\n",
    "\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [e_data, n_data, g_data, e_inds, n_inds]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "# plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot nodes on hole bound\n",
    "plt.scatter(*(n_data['pos']), s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = n_data['pos'][..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# # plot boundary edges\n",
    "# b_edge_index = e_data['edge_index'][..., e_inds['hole_boundary']]\n",
    "# pos1 = n_data['pos'][..., b_edge_index[0]]\n",
    "# pos2 = pos1 + e_data['r'][..., e_inds['hole_boundary']]\n",
    "# x = np.stack((pos1[0], pos2[0]))\n",
    "# y = np.stack((pos1[1], pos2[1]))\n",
    "# plt.plot(x, y, c='green', zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find boundaries holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inds['all_boundaries'] = np.unique(e_data['edge_index'][..., e_inds['all_boundaries']])\n",
    "\n",
    "sides_boundary_nodes = np.concatenate((n_inds['b_bottom'], n_inds['b_top'], n_inds['b_left'], n_inds['b_right'], n_inds['dependent_corner_inds'], n_inds['fixed_corner_ind']))\n",
    "n_inds['sides'] = np.unique(sides_boundary_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inds['hole_boundary'] = np.setdiff1d(n_inds['all_boundaries'], n_inds['sides'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up boundary edges, into sides and hole boundary\n",
    "e_inds['sides'] = np.where(np.isin(e_data['edge_index'], n_inds['sides']).all(axis=0))[0]\n",
    "e_inds['hole_boundary'] = np.where(np.isin(e_data['edge_index'], n_inds['hole_boundary']).all(axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot mesh to check boundary nodes\n",
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='black', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot nodes on hole boundary\n",
    "plt.scatter(*n_data['pos'][:, n_inds['hole_boundary']], marker='x', s=50)\n",
    "\n",
    "# plot boundary edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T[:, e_inds['hole_boundary']]\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='red', alpha=1, zorder=-1)\n",
    "\n",
    "# plot nodes on sides\n",
    "plt.scatter(*n_data['pos'][:, n_inds['sides']], marker='x', s=50)\n",
    "\n",
    "# plot boundary sides\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T[:, e_inds['sides']]\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='green', alpha=1, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "# plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot nodes on hole bound\n",
    "plt.scatter(*(n_data['pos']), s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = n_data['pos'][..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot boundary edges\n",
    "b_edge_index = e_data['edge_index'][..., e_inds['hole_boundary']]\n",
    "pos1 = n_data['pos'][..., b_edge_index[0]]\n",
    "pos2 = pos1 + e_data['r'][..., e_inds['hole_boundary']]\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='green', zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove configurations with overlapping elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check overlap between edges\n",
    "\n",
    "bad_arr = []  # array for indices of loadcases with overlap\n",
    "\n",
    "# iterate over all loadcases\n",
    "for i, pos_temp in enumerate(n_data['pos_final']):\n",
    "    print(i, end=' ')\n",
    "    # pos_temp = pos_temp[:, :, 0].T\n",
    "    pos_temp = pos_temp.T\n",
    "\n",
    "    # coordinates of boundary edges\n",
    "    boundary_edges = e_data['edge_index'][..., e_inds['hole_boundary']].T\n",
    "    n_b_edges = boundary_edges.shape[0]\n",
    "    temp = pos_temp[boundary_edges]\n",
    "\n",
    "    # create all possible pairs of boundary edges\n",
    "    points1 = np.repeat(temp[np.newaxis, ...], n_b_edges, axis=0)\n",
    "    points2 = np.repeat(temp[:, np.newaxis, ...], n_b_edges, axis=1)\n",
    "    points = np.concatenate((points1, points2), axis=2)\n",
    "\n",
    "    # points1.shape = points2.shape = [nr of b edges, nr of b edges, 2, 2]\n",
    "    # points.shape = [nr of b edges, nr of b edges, 4, 2]\n",
    "\n",
    "    # check if a pair of edges intersects\n",
    "    bools = fh.intersect(points)\n",
    "\n",
    "    # exclude edges compared with themselves\n",
    "    temp2 = np.arange(n_b_edges)\n",
    "    bools[temp2, temp2] = False\n",
    "\n",
    "    if bools.any():\n",
    "        print('bad graph!', g_data['F'][i])\n",
    "\n",
    "        # plot all nodes\n",
    "        plt.figure()\n",
    "        plt.scatter(*(pos_temp.T), s=2)\n",
    "\n",
    "        # plot boundary edges\n",
    "        x, y = pos_temp[e_data['edge_index']].T[:, e_inds['hole_boundary']]\n",
    "        x, y = x.T, y.T\n",
    "        plt.plot(x, y, c='tab:blue', alpha=1, zorder=-1)\n",
    "\n",
    "        plt.gca().set_aspect('equal')\n",
    "        plt.grid()\n",
    "\n",
    "        bad_arr.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the figures that were just created in one pdf\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def multipage(filename, figs=None, dpi=200):\n",
    "    pp = PdfPages(filename)\n",
    "    if figs is None:\n",
    "        figs = [plt.figure(n) for n in plt.get_fignums()]\n",
    "    for fig in figs:\n",
    "        fig.savefig(pp, format='pdf')\n",
    "    pp.close()\n",
    "\n",
    "multipage('loadcases_with_overlap.pdf')\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all cases with overlap from the data\n",
    "\n",
    "n_loadcases = len(g_data['F'])\n",
    "\n",
    "bools = np.ones(n_loadcases, dtype=bool)\n",
    "bools[bad_arr] = False\n",
    "\n",
    "for stuff in [e_data, n_data, g_data, n_inds, e_inds]:\n",
    "    for key in stuff:\n",
    "        # check if this is a quantity that has one entry per loadcase\n",
    "        if stuff[key].shape[0] == n_loadcases:\n",
    "            stuff[key] = stuff[key][bools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [e_data, n_data, g_data, e_inds, n_inds]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results, dataframe_file = os.path.split(df_path)\n",
    "path = os.path.join(dir_results,\n",
    "                    'data_'\n",
    "                    + dataframe_file.split('_', maxsplit=1)[1])\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump([e_data, n_data, g_data, e_inds, n_inds], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge boundary nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results, dataframe_file = os.path.split(df_path)\n",
    "path = os.path.join(dir_results,\n",
    "                    'data_'\n",
    "                    + dataframe_file.split('_', maxsplit=1)[1])\n",
    "with open(path, 'rb') as f:\n",
    "    e_data, n_data, g_data, e_inds, n_inds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [e_data, n_data, g_data, e_inds, n_inds]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge right and lower boundary nodes with their counterparts\n",
    "fh.replace(e_data['edge_index'], n_inds['b_top'], n_inds['b_bottom'], inplace=True)\n",
    "fh.replace(e_data['edge_index'], n_inds['b_right'], n_inds['b_left'], inplace=True)\n",
    "fh.replace(e_data['edge_index'], n_inds['dependent_corner_inds'], 3*[n_inds['fixed_corner_ind'][0]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate edges\n",
    "\n",
    "# sort such that edge 0->1 is the same as 1->0\n",
    "temptemp = np.sort(e_data['edge_index'], axis=0)\n",
    "\n",
    "# remove duplicate edges\n",
    "_, inds = np.unique(temptemp, axis=1, return_index=True)\n",
    "print(f'{e_data[\"edge_index\"].shape[-1]} edges, {len(inds)} unique')\n",
    "\n",
    "# indices of edges to keep\n",
    "inds = np.sort(inds)\n",
    "\n",
    "for key in e_data:\n",
    "    e_data[key] = e_data[key][..., inds]\n",
    "for key in e_inds:\n",
    "    # find index into nodes_to_keep of the nodes in n_inds\n",
    "    new_inds = np.searchsorted(inds, e_inds[key])\n",
    "\n",
    "    # keep only the ones that are in nodes_to_keep\n",
    "    e_inds[key] = new_inds[inds[new_inds] == e_inds[key]]\n",
    "\n",
    "# remove unused nodes and relabel the rest\n",
    "nodes_to_keep, e_data['edge_index'] = np.unique(e_data['edge_index'], return_inverse=True)\n",
    "e_data['edge_index'] = e_data['edge_index'].reshape(2, -1)\n",
    "\n",
    "for key in n_inds:\n",
    "    # find index into nodes_to_keep of the nodes in n_inds\n",
    "    new_inds = np.searchsorted(nodes_to_keep, n_inds[key]) % len(nodes_to_keep)\n",
    "\n",
    "    # keep only the ones that are in nodes_to_keep\n",
    "    n_inds[key] = new_inds[nodes_to_keep[new_inds] == n_inds[key]]\n",
    "\n",
    "for key in n_data:\n",
    "    n_data[key] = n_data[key][..., nodes_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot mesh to check boundary nodes\n",
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='black', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot nodes on hole boundary\n",
    "plt.scatter(*n_data['pos'][:, n_inds['hole_boundary']], marker='x', s=50)\n",
    "\n",
    "# plot boundary edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T[:, e_inds['hole_boundary']]\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='red', alpha=1, zorder=-1)\n",
    "\n",
    "# plot nodes on sides\n",
    "plt.scatter(*n_data['pos'][:, n_inds['sides']], marker='x', s=50)\n",
    "\n",
    "# plot boundary sides\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T[:, e_inds['sides']]\n",
    "x, y = x.T, y.T\n",
    "plt.plot(x, y, c='green', alpha=1, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data['pos'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_data['edge_index'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "# plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot nodes on hole bound\n",
    "plt.scatter(*(n_data['pos']), s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = n_data['pos'][..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot boundary edges\n",
    "b_edge_index = e_data['edge_index'][..., e_inds['hole_boundary']]\n",
    "pos1 = n_data['pos'][..., b_edge_index[0]]\n",
    "pos2 = pos1 + e_data['r'][..., e_inds['hole_boundary']]\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='green', zorder=-1)\n",
    "\n",
    "# plot copy\n",
    "# plot nodes on hole bound\n",
    "pos_temp = n_data['pos'] + [[3.2], [0]]\n",
    "plt.scatter(*(pos_temp), s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = pos_temp[..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bulk nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_bulk_nodes:\n",
    "    # remove nodes not at the hole boundaries and relabel the rest\n",
    "    nodes_to_keep = np.copy(n_inds['hole_boundary'])\n",
    "\n",
    "    for key in n_inds:\n",
    "        # find index into nodes_to_keep of the nodes in n_inds\n",
    "        new_inds = np.searchsorted(nodes_to_keep, n_inds[key]) % len(nodes_to_keep)\n",
    "\n",
    "        # keep only the ones that are in nodes_to_keep\n",
    "        n_inds[key] = new_inds[nodes_to_keep[new_inds] == n_inds[key]]\n",
    "\n",
    "    for key in n_data:\n",
    "        n_data[key] = n_data[key][..., nodes_to_keep]\n",
    "\n",
    "    for key in e_data:\n",
    "        e_data[key] = e_data[key][..., e_inds['hole_boundary']]\n",
    "\n",
    "    e_inds['hole_boundary'] = np.arange(e_data['edge_index'].shape[-1])\n",
    "    fh.replace(e_data['edge_index'], nodes_to_keep, np.arange(len(nodes_to_keep)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_bulk_nodes:\n",
    "    pos_temp = n_data['pos'].T\n",
    "    n_nodes = n_data['pos'].shape[1]\n",
    "\n",
    "    # find quadrant of each boundary node\n",
    "    n_data['quad'] = np.zeros(n_nodes, dtype=int)\n",
    "    n_data['quad'][pos_temp[:, 0] > 0] += 1  # x-coordinate in right half\n",
    "    n_data['quad'][pos_temp[:, 1] > 0] += 2  # y-coordinate in upper half"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tile RVEs - old way (not exactly the same mesh tiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tile RVEs\n",
    "# tiling = [2, 2]\n",
    "# basis_vecs = np.array([[3.2, 0], [0, 3.2]]).reshape(2, 2, 1)\n",
    "# n_loadcases = len(n_data['pos_final'])\n",
    "\n",
    "# n_data_new = {'pos': np.array([]).reshape(2, 0), 'quad': np.array([], dtype=int), 'pos_final': np.array([]).reshape(n_loadcases, 2, 0)}\n",
    "# for i in range(tiling[0]):\n",
    "#     for j in range(tiling[1]):\n",
    "#         pos2 = n_data['pos'] + i*basis_vecs[0] + j*basis_vecs[1]\n",
    "#         quad2 = n_data['quad'] + 4*(tiling[1]*i + j)\n",
    "#         n_data_new['pos'] = np.concatenate((n_data_new['pos'], pos2), axis=-1)\n",
    "#         n_data_new['quad'] = np.concatenate((n_data_new['quad'], quad2))\n",
    "\n",
    "#         basis_vecs2 = np.einsum('ijk,lkm->ijkm', g_data['F'], basis_vecs)\n",
    "#         pos_final2 = n_data['pos_final'] + i*basis_vecs2[:, 0] + j*basis_vecs2[:, 1]\n",
    "#         n_data_new['pos_final'] = np.concatenate((n_data_new['pos_final'],\n",
    "#                                                   pos_final2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_RVEs = np.prod(tiling)\n",
    "# n_edges = e_data['edge_index'].shape[-1]\n",
    "\n",
    "# # all RVE copies get the same edges\n",
    "# e_data['edge_index'] = np.repeat(e_data['edge_index'].reshape(2, n_edges, 1), n_RVEs, axis=-1)\n",
    "# e_data['r'] = np.repeat(e_data['r'].reshape(2, n_edges, 1), n_RVEs, axis=-1).reshape(2, -1)\n",
    "# e_data['d'] = np.repeat(e_data['d'].reshape(n_edges, 1), n_RVEs, axis=-1).flatten()\n",
    "# e_inds['hole_boundary'] = np.repeat(e_data['edge_index'].reshape(-1, 1), n_RVEs, axis=-1)\n",
    "\n",
    "# # but nodes they connect must be incremented\n",
    "# e_data['edge_index'] += np.arange(n_RVEs)*n_edges\n",
    "# e_data['edge_index'] = e_data['edge_index'].reshape(2, -1)\n",
    "# e_inds['hole_boundary'] += np.arange(n_RVEs)*n_edges\n",
    "# e_inds['hole_boundary'] = e_inds['hole_boundary'].flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_data = n_data_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_bulk_nodes:\n",
    "    mode = 'connect3'\n",
    "\n",
    "    n_quads = n_data['quad'].max()+1\n",
    "    print(n_quads)\n",
    "    edges_new = np.stack((x.flatten(), y.flatten()), axis=1)\n",
    "    print(edges_new.shape)\n",
    "    edges_new = []\n",
    "    pos_temp = n_data['pos'].T\n",
    "\n",
    "    if mode == 'all':\n",
    "        n_nodes = pos_temp.shape[0]\n",
    "        x, y = np.meshgrid(np.arange(n_nodes), np.arange(n_nodes))\n",
    "        edges_new = np.stack((x.flatten(), y.flatten()), axis=1)\n",
    "\n",
    "        # remove self loops\n",
    "        edges_new = edges_new[edges_new[:, 0] != edges_new[:, 1]]\n",
    "\n",
    "\n",
    "    # each node gets 3 connections: one to closest node of each hole\n",
    "    if mode == 'connect3':\n",
    "        for q in range(n_quads):\n",
    "            # nodes around hole in quadrant q (q-hole)\n",
    "            hole_nodes = np.where(n_data['quad'] == q)[0]\n",
    "\n",
    "            temp = []\n",
    "            d_temp2 = []\n",
    "            # for each node in q-hole, find nearest node in each other hole\n",
    "            for q2 in range(n_quads):\n",
    "                if q == q2: continue\n",
    "\n",
    "                other_hole_nodes = np.where(n_data['quad'] == q2)[0]\n",
    "\n",
    "                # distances between nodes around hole q and nodes around hole q2\n",
    "                r_temp = pos_temp[hole_nodes].reshape(-1, 1, 2) - pos_temp[other_hole_nodes].reshape(1, -1, 2)\n",
    "\n",
    "                r_temp[r_temp > 1.6] = -1.6*2 + r_temp[r_temp > 1.6]\n",
    "                r_temp[r_temp < -1.6] = 1.6*2 + r_temp[r_temp < -1.6]\n",
    "                d_temp = np.linalg.norm(r_temp, axis=-1)\n",
    "                # d_temp.shape = [nr of nodes on hole q, nr of nodes on hole q2]\n",
    "\n",
    "                inds = np.argmin(d_temp, axis=1)\n",
    "                closest_nodes = other_hole_nodes[inds]\n",
    "\n",
    "                temp.append(np.stack((hole_nodes, closest_nodes), axis=-1))\n",
    "                d_temp2.append(d_temp[np.arange(len(inds)), inds])\n",
    "\n",
    "            inds = np.argsort(d_temp2, axis=0)\n",
    "            temp = np.array(temp)\n",
    "\n",
    "            edges_new.extend(np.take_along_axis(temp, inds[:3][..., np.newaxis], axis=0))\n",
    "\n",
    "        edges_new = np.array(edges_new).reshape(-1, 2)\n",
    "\n",
    "    # each node gets 1 connection: one to closest node of another hole\n",
    "    if mode == 'connect1':\n",
    "        raise NotImplementedError('connect1 not yet implemented')\n",
    "        for q in range(4):\n",
    "            # nodes around hole in quadrant q (q-hole)\n",
    "            hole_nodes = n_inds['hole_boundary'][quad == q]\n",
    "\n",
    "            other_hole_nodes = n_inds['hole_boundary'][quad != q]\n",
    "\n",
    "            # distances between nodes around hole q and nodes around all other holes\n",
    "            r_temp = pos_temp[hole_nodes].reshape(-1, 1, 2) - pos_temp[other_hole_nodes].reshape(1, -1, 2)\n",
    "\n",
    "            r_temp[r_temp > 1.6] = -1.6*2 + r_temp[r_temp > 1.6]\n",
    "            r_temp[r_temp < -1.6] = 1.6*2 + r_temp[r_temp < -1.6]\n",
    "            d_temp = np.linalg.norm(r_temp, axis=-1)\n",
    "\n",
    "            closest_nodes = other_hole_nodes[np.argmin(d_temp, axis=1)]\n",
    "            edges_new.extend(zip(hole_nodes, closest_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_bulk_nodes:\n",
    "    edges_new = np.array(edges_new)\n",
    "    # deduplicate edges\n",
    "    print('edges before deduplicating:', edges_new.shape)\n",
    "    edges_new = np.sort(edges_new, axis=1)\n",
    "    edges_new, counts = np.unique(edges_new, axis=0, return_counts=True)\n",
    "    print('edges after deduplicating :', edges_new.shape)\n",
    "    edges_new = edges_new.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_bulk_nodes:\n",
    "    # new set of edges: original edges at the hole boundary + newly created edges\n",
    "    # redefine e_data (all old data can be thrown away, needs to be recalculated)\n",
    "    if mode == 'all':\n",
    "        # deduplicate again\n",
    "        n_boundary = e_data['edge_index'].shape[-1]\n",
    "        edges_new = np.concatenate((e_data['edge_index'], edges_new), axis=1)\n",
    "        edges_new, inv = np.unique(edges_new, axis=1, return_inverse=True)\n",
    "\n",
    "        e_inds = {'hole_boundary': inv[:n_boundary]}\n",
    "        e_data = {'edge_index': edges_new}\n",
    "    else:\n",
    "        e_inds = {'hole_boundary': np.arange(e_data['edge_index'].shape[-1])}\n",
    "        e_data = {'edge_index': np.concatenate((e_data['edge_index'], edges_new), axis=1)}\n",
    "\n",
    "    e_data['r'] = pos_temp[e_data['edge_index'][1]] - pos_temp[e_data['edge_index'][0]]\n",
    "    e_data['r'][e_data['r'] > 1.6] = -1.6*2 + e_data['r'][e_data['r'] > 1.6]\n",
    "    e_data['r'][e_data['r'] < -1.6] = 1.6*2 + e_data['r'][e_data['r'] < -1.6]\n",
    "    e_data['r'] = e_data['r'].T\n",
    "    e_data['d'] = np.linalg.norm(e_data['r'], axis=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "font = {\n",
    "        # 'family' : 'normal',\n",
    "        # 'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# plot all nodes in original location\n",
    "# plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot nodes on hole boundary\n",
    "plt.scatter(*n_data['pos'], s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = n_data['pos'][..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot boundary edges\n",
    "b_edge_index = e_data['edge_index'][..., e_inds['hole_boundary']]\n",
    "pos1 = n_data['pos'][..., b_edge_index[0]]\n",
    "pos2 = pos1 + e_data['r'][..., e_inds['hole_boundary']]\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='green', zorder=-1)\n",
    "\n",
    "# set tick interval x and y axes the same\n",
    "stepsize = 1\n",
    "# x\n",
    "start, end = plt.gca().get_xlim()\n",
    "start = np.ceil(start/stepsize)*stepsize\n",
    "end = np.ceil(end/stepsize)*stepsize\n",
    "plt.gca().xaxis.set_ticks(np.arange(start, end, stepsize))\n",
    "plt.gca().xaxis.set_ticks(np.arange(start, end, stepsize))\n",
    "# y\n",
    "start, end = plt.gca().get_ylim()\n",
    "start = np.ceil(start/stepsize)*stepsize\n",
    "end = np.ceil(end/stepsize)*stepsize\n",
    "plt.gca().yaxis.set_ticks(np.arange(start, end, stepsize))\n",
    "plt.gca().yaxis.set_ticks(np.arange(start, end, stepsize))\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [e_data, n_data, g_data, e_inds, n_inds]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results, dataframe_file = os.path.split(df_path)\n",
    "path = os.path.join(dir_results,\n",
    "                    'data2_'\n",
    "                    + dataframe_file.split('_', maxsplit=1)[1])\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump([e_data, n_data, g_data, e_inds, n_inds], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tile RVEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_results, dataframe_file = os.path.split(df_path)\n",
    "path = os.path.join(dir_results,\n",
    "                    'data2_'\n",
    "                    + dataframe_file.split('_', maxsplit=1)[1])\n",
    "with open(path, 'rb') as f:\n",
    "    e_data, n_data, g_data, e_inds, n_inds = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tile RVEs\n",
    "tiling = None  # [2, 2]\n",
    "\n",
    "if tiling is not None:\n",
    "    basis_vecs = np.array([[3.2, 0], [0, 3.2]]).reshape(2, 2, 1)\n",
    "    nr_loadcases = len(n_data['pos_final'])\n",
    "    nr_nodes = n_data['pos'].shape[-1]\n",
    "    nr_edges = e_data['edge_index'].shape[-1]\n",
    "\n",
    "    e_data_new = {'edge_index': np.array([], dtype=int).reshape(2, 0),\n",
    "                'r': np.array([], dtype=int).reshape(2, 0),\n",
    "                'd': np.array([], dtype=int),}\n",
    "    e_inds_new = {'hole_boundary': np.array([], dtype=int)}\n",
    "    n_data_new = {'pos': np.array([]).reshape(2, 0), 'quad': np.array([], dtype=int), 'pos_final': np.array([]).reshape(nr_loadcases, 2, 0)}\n",
    "    for i in range(tiling[0]):\n",
    "        for j in range(tiling[1]):\n",
    "            pos2 = n_data['pos'] + i*basis_vecs[0] + j*basis_vecs[1]\n",
    "            quad2 = n_data['quad'] + 4*(tiling[1]*i + j)\n",
    "            edge_index2 = e_data['edge_index'] + nr_nodes*(tiling[1]*i + j)\n",
    "\n",
    "            n_data_new['pos'] = np.concatenate((n_data_new['pos'], pos2), axis=-1)\n",
    "            n_data_new['quad'] = np.concatenate((n_data_new['quad'], quad2))\n",
    "            e_data_new['edge_index'] = np.concatenate((e_data_new['edge_index'], edge_index2), axis=1)\n",
    "\n",
    "            basis_vecs2 = np.einsum('ijk,lkm->ijkm', g_data['F'], basis_vecs)\n",
    "            pos_final2 = n_data['pos_final'] + i*basis_vecs2[:, 0] + j*basis_vecs2[:, 1]\n",
    "            n_data_new['pos_final'] = np.concatenate((n_data_new['pos_final'],\n",
    "                                                    pos_final2), axis=-1)\n",
    "\n",
    "            e_data_new['r'] = np.concatenate((e_data_new['r'], e_data['r']), axis=1)\n",
    "            e_data_new['d'] = np.concatenate((e_data_new['d'], e_data['d']), axis=0)\n",
    "            e_inds_new['hole_boundary'] = np.concatenate(\n",
    "                (e_inds_new['hole_boundary'],\n",
    "                e_inds['hole_boundary'] + nr_edges*(tiling[1]*i + j)\n",
    "                ), axis=0\n",
    "            )\n",
    "    # move edges to different neighbors\n",
    "\n",
    "    r_real = (n_data_new['pos'][..., e_data_new['edge_index'][1]]\n",
    "            - n_data_new['pos'][..., e_data_new['edge_index'][0]])\n",
    "\n",
    "    # check if edge too wide in x-direction\n",
    "    bools = np.abs(r_real[0]) > 1.6\n",
    "    e_data_new['edge_index'][1, bools] -= 2*nr_nodes\n",
    "    e_data_new['edge_index'][1, bools] %= 4*nr_nodes\n",
    "\n",
    "    # check if edge too wide in y-direction\n",
    "    bools = np.abs(r_real[1]) > 1.6\n",
    "    bools2 = e_data_new['edge_index'][1] < nr_nodes*2\n",
    "    e_data_new['edge_index'][1, bools*bools2] += nr_nodes\n",
    "    e_data_new['edge_index'][1, bools*bools2] %= 2*nr_nodes\n",
    "    bools3 = e_data_new['edge_index'][1] >= nr_nodes*2\n",
    "    e_data_new['edge_index'][1, bools*bools3] -= 3*nr_nodes\n",
    "    e_data_new['edge_index'][1, bools*bools3] %= 2*nr_nodes\n",
    "    e_data_new['edge_index'][1, bools*bools3] += 2*nr_nodes\n",
    "    n_data = n_data_new\n",
    "    e_data = e_data_new\n",
    "    e_inds = e_inds_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['e_data', 'n_data', 'g_data', 'e_inds', 'n_inds']\n",
    "for stuff, name in zip([e_data, n_data, g_data, e_inds, n_inds], names):\n",
    "    print(f'=============== {name} ===============')\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all edges, by r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in original location\n",
    "# plt.scatter(*(n_data['pos']), c='black', s=1)  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot nodes on hole bound\n",
    "plt.scatter(*(n_data['pos']), s=10)  #, marker='x', s=50, c=quad)\n",
    "\n",
    "# plot edges\n",
    "pos1 = n_data['pos'][..., e_data['edge_index'][0]]\n",
    "pos2 = pos1 + e_data['r']\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='red', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot boundary edges\n",
    "b_edge_index = e_data['edge_index'][..., e_inds['hole_boundary']]\n",
    "pos1 = n_data['pos'][..., b_edge_index[0]]\n",
    "pos2 = pos1 + e_data['r'][..., e_inds['hole_boundary']]\n",
    "x = np.stack((pos1[0], pos2[0]))\n",
    "y = np.stack((pos1[1], pos2[1]))\n",
    "plt.plot(x, y, c='green', zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot all edges from point to point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot meshes\n",
    "%matplotlib qt\n",
    "try:\n",
    "    # plot all nodes in original location\n",
    "    plt.scatter(*(n_data['pos']), #c='tab:blue',\n",
    "                s=1, c=n_data['quad'], cmap='tab20')\n",
    "except KeyError:\n",
    "    # plot all nodes in original location\n",
    "    plt.scatter(*(n_data['pos']), #c='tab:blue',\n",
    "                s=1, cmap='tab20')\n",
    "\n",
    "# plot edges\n",
    "x, y = n_data['pos'].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "print(x.shape)\n",
    "bools = (np.abs(x[0] - x[1]) < 1.6)*(np.abs(y[0] - y[1]) < 1.6)\n",
    "plt.plot(x[:, bools], y[:, bools], c='tab:blue', alpha=0.3, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data['pos_final'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot meshes\n",
    "%matplotlib qt\n",
    "\n",
    "# plot all nodes in final location\n",
    "plt.scatter(*(n_data['pos_final'][0]), #c='tab:green',\n",
    "            s=1, c='red')  #, c=n_data['quad'], cmap='tab20')  #, s=50, alpha=0.5)\n",
    "\n",
    "# plot edges in final location\n",
    "x, y = n_data['pos_final'][0].T[e_data['edge_index']].T\n",
    "x, y = x.T, y.T\n",
    "bools = (np.abs(x[0] - x[1]) < 1.6)*(np.abs(y[0] - y[1]) < 1.6)\n",
    "plt.plot(x[:, bools], y[:, bools], c='tab:blue', alpha=0.3, zorder=-1)\n",
    "\n",
    "# plot boundary edges in final location\n",
    "x, y = n_data['pos_final'][0].T[e_data['edge_index'][..., e_inds['hole_boundary']]].T\n",
    "x, y = x.T, y.T\n",
    "bools = (np.abs(x[0] - x[1]) < 1.6)*(np.abs(y[0] - y[1]) < 1.6)\n",
    "plt.plot(x[:, bools], y[:, bools], c='tab:green', alpha=0.3, zorder=-1)\n",
    "\n",
    "# make plot pretty\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.grid()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicate edges to make the graph undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = e_data['edge_index'].shape[-1]\n",
    "for key in e_inds:\n",
    "    e_inds[key] = np.concatenate((e_inds[key], e_inds[key]+n_edges), axis=-1)\n",
    "\n",
    "e_data['edge_index'] = np.concatenate((e_data['edge_index'],\n",
    "    np.flip(e_data['edge_index'], axis=0)), axis=-1)\n",
    "\n",
    "e_data['r'] = np.concatenate((e_data['r'], -e_data['r']), axis=-1)\n",
    "e_data['d'] = np.concatenate((e_data['d'], e_data['d']), axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn data into graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [e_data, n_data, g_data, e_inds, n_inds]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # boundary info in edges:\n",
    "x = np.array([]).reshape(n_data['pos'].shape[-1], -1)\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "edge_attr = torch.ones((e_data['edge_index'].shape[1], 1), dtype=torch.float)\n",
    "edge_attr[e_inds['hole_boundary']] = -1\n",
    "\n",
    "# # boundary info in nodes:\n",
    "# x = torch.ones(len(nodes_to_keep), 1)\n",
    "# x[hole_boundary_nodes2] = -1\n",
    "# edge_attr = torch.tensor([]).reshape(edges2.shape[1], 0) # edge attributes should be empty for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into tensors\n",
    "\n",
    "# edge indices attributes that are the same for each graph\n",
    "edge_index = torch.tensor(e_data['edge_index'], dtype=torch.long)\n",
    "\n",
    "d = torch.tensor(e_data['d'], dtype=torch.float)[..., np.newaxis]\n",
    "r = torch.tensor(e_data['r'], dtype=torch.float)\n",
    "\n",
    "pos = torch.tensor(n_data['pos'], dtype=torch.float)\n",
    "\n",
    "# node attributes that vary per graph\n",
    "pos_final = torch.tensor(np.transpose(n_data['pos_final'], [0, 2, 1]),\n",
    "                          dtype=torch.float)\n",
    "\n",
    "# graph attributes\n",
    "g_data2 = {key: torch.tensor(g_data[key], dtype=torch.float) for key in ['F', 'W', 'P', 'D']}\n",
    "# for key in ['P', 'D', 'F']:\n",
    "#     g_data2[key] = g_data2[key].unsqueeze(1)\n",
    "g_data2['traj'] = torch.tensor(g_data['traj'], dtype=torch.long).reshape(-1)\n",
    "g_data2['W'] = g_data2['W'].reshape(-1)/((2*1.6)**2)  # divide by volume to get density\n",
    "g_data2['mean_pos'] = torch.mean(pos_final, dim=1) #.reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stuff in [g_data2]:\n",
    "    for key in stuff:\n",
    "        print(f'{key+\".shape\":30}\\t', stuff[key].shape)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if constant_mesh:\n",
    "    # make list of graph objects, one for each F\n",
    "    data_list0 = []\n",
    "    for i in range(len(pos_final)):\n",
    "        data_list0.append(\n",
    "            tg.data.Data(\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_attr,\n",
    "                x=x,\n",
    "                y=pos_final[i].clone(),\n",
    "                pos=pos.T.clone(),\n",
    "                r=r.T.clone(),\n",
    "                d=d.clone(),\n",
    "                **{key: g_data2[key][[i]].clone() for key in g_data2}\n",
    "            )\n",
    "        )\n",
    "else:\n",
    "    raise NotImplementedError('variable mesh not implemented yet')\n",
    "\n",
    "print('data_list0[0]:', data_list0[0])\n",
    "print('data_list0[0] undirected:', end=' ')\n",
    "print(tg.utils.is_undirected(data_list0[0].edge_index, data_list0[0].edge_attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types and size of tensors in memory\n",
    "print(f'{\"variable\":12} {\"type\":23} {\"size (bytes)\":>13} {\"shape\":24} {\"datatype\":15} {\"bytes per element\"}')\n",
    "for name, value in data_list0[0]:\n",
    "    if value.numel() > 0:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15} {sys.getsizeof(value.storage())/value.numel()}')\n",
    "    else:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(gr_path, 'wb') as f:\n",
    "    pickle.dump(data_list0, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nr of nodes:\\t', len(x))\n",
    "print('Nr of edges:\\t', len(edge_attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate shortest path length between two most distant nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(e_data['edge_index'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(nx.all_pairs_shortest_path_length(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxes_temp = []\n",
    "for i, [node, node_dict] in enumerate(nx.all_pairs_shortest_path_length(G)):\n",
    "    maxes_temp.append(max(node_dict.values()))\n",
    "print(max(maxes_temp))\n",
    "longest_path_length = max(maxes_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.qmc import LatinHypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_path = f'data\\\\coarseMesh_noBifurcation_5\\\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_2.pkl'\n",
    "with open(gr_path, 'rb') as f:\n",
    "    data_list0 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_factor = 1\n",
    "\n",
    "sampler = LatinHypercube(d=4, seed=43)\n",
    "sample = sampler.random(n=len(data_list0)*augmentation_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list1 = []\n",
    "\n",
    "j = 0\n",
    "for graph in data_list0:\n",
    "    for i in range(augmentation_factor):\n",
    "        reflection1, reflection2, rotation, scaling = sample[j]\n",
    "\n",
    "        reflection1 = np.round(reflection1)*2-1  # either -1 or 1\n",
    "        reflection2 = np.round(reflection2)*2-1  # either -1 or 1\n",
    "        A = np.array([[1.0*reflection1, 0], [0, 1.0*reflection2]])\n",
    "\n",
    "        scale_factor = 10**(2*scaling-1)  # between 0.1 and 10\n",
    "        S = np.array([[scale_factor, 0], [0, scale_factor]])\n",
    "\n",
    "        phi = rotation*2*np.pi\n",
    "        R = np.array([[np.cos(phi), -np.sin(phi)],\n",
    "                      [np.sin(phi), np.cos(phi)]])\n",
    "\n",
    "        T = torch.tensor(R@S@A, dtype=torch.float)\n",
    "        T2 = torch.tensor(np.matmul(R, A), dtype=torch.float)\n",
    "\n",
    "        graph2 = graph.clone()\n",
    "\n",
    "        # apply reflection, rotation and scaling to vectors\n",
    "        graph2.y = torch.matmul(T, graph2.y.T).T\n",
    "        graph2.pos = torch.matmul(T, graph2.pos.T).T\n",
    "        graph2.r = torch.matmul(T, graph2.r.T).T\n",
    "        graph2.mean_pos = torch.matmul(T, graph2.mean_pos.T).T\n",
    "\n",
    "        # apply scaling\n",
    "        graph2.d = scale_factor*graph2.d\n",
    "\n",
    "        # apply reflection and rotation to the tensors\n",
    "        graph2.P = torch.einsum('lj,ijk,km->ilm', T2, graph2.P, T2.T)\n",
    "        graph2.D = torch.einsum('nj,ok,pl,qm,ijklm->inopq', T2, T2, T2, T2, graph2.D)\n",
    "        graph2.F = torch.einsum('ij,lk,mjk->mil', T2, T2, graph2.F)\n",
    "        graph2.reflection = torch.tensor([reflection1, reflection2])\n",
    "        graph2.phi = torch.tensor([phi])\n",
    "        graph2.scale_factor = torch.tensor([scale_factor])\n",
    "\n",
    "        data_list1.append(graph2)\n",
    "\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types and size of tensors in memory\n",
    "print(f'{\"variable\":12} {\"type\":23} {\"size (bytes)\":>13} {\"shape\":24} {\"datatype\":15} {\"bytes per element\"}')\n",
    "\n",
    "nr_of_bytes = 0\n",
    "for name, value in data_list0[0]:\n",
    "    if value.numel() > 0:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15} {sys.getsizeof(value.storage())/value.numel()}')\n",
    "    else:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15}')\n",
    "\n",
    "    nr_of_bytes += sys.getsizeof(value.storage())\n",
    "print(nr_of_bytes)\n",
    "print(nr_of_bytes*len(data_list0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types and size of tensors in memory\n",
    "print(f'{\"variable\":12} {\"type\":23} {\"size (bytes)\":>13} {\"shape\":24} {\"datatype\":15} {\"bytes per element\"}')\n",
    "\n",
    "nr_of_bytes = 0\n",
    "for name, value in data_list1[0]:\n",
    "    if value.numel() > 0:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15} {sys.getsizeof(value.storage())/value.numel()}')\n",
    "    else:\n",
    "        print(f'{name:12} {str(type(value)):23} {sys.getsizeof(value.storage()):>13} {str(value.shape):24} {str(value.dtype):15}')\n",
    "\n",
    "    nr_of_bytes += sys.getsizeof(value.storage())\n",
    "print(nr_of_bytes)\n",
    "print(nr_of_bytes*len(data_list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "# choose one graph to plot\n",
    "graph = data_list1[126].clone()\n",
    "print('reflection', graph.reflection)\n",
    "print('scale_factor', graph.scale_factor)\n",
    "print('phi', graph.phi)\n",
    "\n",
    "# create figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# use initial position to exclude wraparound edges\n",
    "graph_indices = graph.edge_index.detach().numpy()\n",
    "pos_init = graph.pos.clone().detach().numpy().reshape(-1, 2)  # original\n",
    "x, y = np.transpose(pos_init[graph_indices], axes=[2,0,1])\n",
    "bools = ((np.abs(np.diff(x, axis=0)) < 1.6*graph.scale_factor[0].item())\n",
    "            & (np.abs(np.diff(y, axis=0)) < 1.6*graph.scale_factor[0].item())\n",
    "        ).flatten()\n",
    "\n",
    "# get all relevant positions\n",
    "graph.batch = torch.zeros(len(graph.x), dtype=torch.long)\n",
    "# pos_pred = model(graph)[0].clone().detach().numpy()  # predicted\n",
    "pos_FEM = graph.y.clone().detach().numpy()  # target\n",
    "\n",
    "# plot nodes\n",
    "ax.scatter(*(pos_FEM.T), label='final position', s=1)\n",
    "# ax.scatter(*(pos_pred.T), label='GNN prediction', s=1)\n",
    "\n",
    "# plot edges FEM\n",
    "x, y = np.transpose(pos_FEM[graph_indices], axes=[2,0,1])\n",
    "edges_FEM = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:green')  #, label='final position')\n",
    "\n",
    "# plot edges predicted\n",
    "# x, y = np.transpose(pos_pred[graph_indices], axes=[2,0,1])\n",
    "# edges_pred = ax.plot(x[:, bools], y[:, bools], alpha=0.3, c='tab:orange')\n",
    "\n",
    "# plot original locations corners\n",
    "corner_coords = np.array([[-1.6, -1.6, 1.6, 1.6],[-1.6, 1.6, -1.6, 1.6]])\n",
    "orig_corners = ax.scatter(*corner_coords, marker='x', label='original corners', c='red', s=20)\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# make plots pretty\n",
    "ax.grid()\n",
    "ax.axis('off')\n",
    "ax.margins(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_path2 = 'data\\\\coarseMesh_noBifurcation_5\\\\graphs_coarseMesh_noBifurcation_diameter_0.9_5_noBulkNodes_2_augmented_' + str(augmentation_factor) + '.pkl'\n",
    "with open(gr_path2, 'wb') as f:\n",
    "    pickle.dump(data_list1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env_ML2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17af4917c1f6b053a3c10937d0fabbfd2f76d8d1823238a27a1a051833d930bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
